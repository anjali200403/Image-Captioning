{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "S9Pmy7cERsaU"
      },
      "outputs": [],
      "source": [
        "from keras.applications.vgg16 import VGG16\n",
        "from keras.preprocessing.image import load_img\n",
        "from keras.preprocessing.image import img_to_array\n",
        "from keras.applications.vgg16 import preprocess_input\n",
        "from keras.models import Model\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "mKfKNuq3kQEV"
      },
      "outputs": [],
      "source": [
        "image_dataset_path = '/content/drive/MyDrive/codetice/input/Flicker8k_Dataset'\n",
        "caption_dataset_path = '/content/drive/MyDrive/codetice/input/Flickr8k_text/Flickr8k.token.txt'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "XO2QUc22h7qT"
      },
      "outputs": [],
      "source": [
        "# load the caption file & read it\n",
        "def load_caption_file(path):\n",
        "\n",
        "    # dictionary to store captions\n",
        "    captions_dict = {}\n",
        "\n",
        "    # iterate through the file\n",
        "    for caption in open(path):\n",
        "\n",
        "        # caption has format-> 1000268201_693b08cb0e.jpg#0  A child in a pink dress is climbing up a set of stairs in an entry way .\n",
        "        tokens = caption.split()\n",
        "        caption_id, caption_text = tokens[0].split('.')[0], tokens[1:]\n",
        "        caption_text = ' '.join(caption_text)\n",
        "\n",
        "        # save it in the captions dictionary\n",
        "        if caption_id not in captions_dict:\n",
        "            captions_dict[caption_id] = caption_text\n",
        "\n",
        "    return captions_dict\n",
        "\n",
        "# call the function\n",
        "captions_dict = load_caption_file(caption_dataset_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "taYAPKQx7avL"
      },
      "outputs": [],
      "source": [
        "# clean the captions\n",
        "import string\n",
        "\n",
        "# dictionary to store the cleaned captions\n",
        "new_captions_dict = {}\n",
        "\n",
        "# prepare translation table for removing punctuation. third argument is the list of punctuations we want to remove\n",
        "table = str.maketrans('', '', string.punctuation)\n",
        "\n",
        "# loop through the dictionary\n",
        "for caption_id, caption_text in captions_dict.items():\n",
        "    # tokenize the caption_text\n",
        "    caption_text = caption_text.split()\n",
        "    # convert it into lower case\n",
        "    caption_text = [token.lower() for token in caption_text]\n",
        "    # remove punctuation from each token\n",
        "    caption_text = [token.translate(table) for token in caption_text]\n",
        "    # remove all the single letter tokens like 'a', 's'\n",
        "    caption_text = [token for token in caption_text if len(token)>1]\n",
        "    # store the cleaned captions\n",
        "    new_captions_dict[caption_id] = 'startseq ' + ' '.join(caption_text) + ' endseq'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "J9ymD8qQjuRN"
      },
      "outputs": [],
      "source": [
        "# delete unwanted\n",
        "del captions_dict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "asfL1u9_79WG",
        "outputId": "fba5de35-08b8-468b-e16b-937d06a9bade"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\"1000268201_693b08cb0e\" : startseq child in pink dress is climbing up set of stairs in an entry way endseq\n"
          ]
        }
      ],
      "source": [
        "print('\"' + list(new_captions_dict.keys())[0] + '\"' + ' : ' + new_captions_dict[list(new_captions_dict.keys())[0]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jlws8Uqx8AQq",
        "outputId": "272c91c7-d055-4664-9370-452440e106f5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "8092"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "len(new_captions_dict)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "S7byudit8DKW"
      },
      "outputs": [],
      "source": [
        "caption_images_list = []\n",
        "\n",
        "image_index = list(new_captions_dict.keys())\n",
        "\n",
        "caption_images_list = [ image.split('.')[0] for image in os.listdir(image_dataset_path) if image.split('.')[0] in image_index ]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "tpM1FATM8F52",
        "outputId": "ffb609cc-cf12-4890-d184-a2647cd031b3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'3726730085_2468ee9220'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "caption_images_list[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A59lcGtZ8Imd",
        "outputId": "ff1f7996-de26-4c8c-968e-03191e5b1ee0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "8091"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "len(caption_images_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "2GcyBc_W8MFD"
      },
      "outputs": [],
      "source": [
        "train_validate_images = caption_images_list[0:8081]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W1eFwbZv8P-7",
        "outputId": "27be623e-7266-4ef3-92bc-d6e73be359e4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['111766423_4522d36e56',\n",
              " '112243673_fd68255217',\n",
              " '1131804997_177c3c0640',\n",
              " '1094462889_f9966dafa6',\n",
              " '1141739219_2c47195e4c',\n",
              " '109823397_e35154645f',\n",
              " '109260216_85b0be5378',\n",
              " '1107246521_d16a476380',\n",
              " '111537217_082a4ba060',\n",
              " '109738916_236dc456ac']"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "test_images = caption_images_list[8081:8091]\n",
        "test_images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "POH8k-_M8R8F"
      },
      "outputs": [],
      "source": [
        "# extract features from each photo in the directory\n",
        "def extract_features(directory, image_keys):\n",
        "    # load the model\n",
        "    model = VGG16()\n",
        "\n",
        "    # re-structure the model\n",
        "    model = Model(inputs=model.inputs, outputs=model.layers[-2].output)\n",
        "\n",
        "    # summarize\n",
        "    print(model.summary())\n",
        "\n",
        "    # extract features from each photo\n",
        "    features = dict()\n",
        "\n",
        "    for name in image_keys:\n",
        "\n",
        "        # load an image from file\n",
        "        filename = directory + '/' + name + '.jpg'\n",
        "\n",
        "        # load the image and convert it into target size of 224*224\n",
        "        image = load_img(filename, target_size=(224, 224))\n",
        "\n",
        "        # convert the image pixels to a numpy array\n",
        "        image = img_to_array(image)\n",
        "\n",
        "        # reshape data for the model\n",
        "        image = image.reshape((1, image.shape[0], image.shape[1], image.shape[2]))\n",
        "\n",
        "        # prepare the image for the VGG model\n",
        "        image = preprocess_input(image)\n",
        "\n",
        "        # get features\n",
        "        feature = model.predict(image, verbose=0)\n",
        "\n",
        "        # get image id\n",
        "        image_id = name.split('.')[0]\n",
        "\n",
        "        # store feature\n",
        "        features[image_id] = feature\n",
        "\n",
        "#         print('>%s' % name)\n",
        "\n",
        "\n",
        "    return features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5w9c8eEJ8Xdd",
        "outputId": "40dec34e-52b9-40e2-fd24-e6955737c897"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
            "                                                                 \n",
            " block1_conv1 (Conv2D)       (None, 224, 224, 64)      1792      \n",
            "                                                                 \n",
            " block1_conv2 (Conv2D)       (None, 224, 224, 64)      36928     \n",
            "                                                                 \n",
            " block1_pool (MaxPooling2D)  (None, 112, 112, 64)      0         \n",
            "                                                                 \n",
            " block2_conv1 (Conv2D)       (None, 112, 112, 128)     73856     \n",
            "                                                                 \n",
            " block2_conv2 (Conv2D)       (None, 112, 112, 128)     147584    \n",
            "                                                                 \n",
            " block2_pool (MaxPooling2D)  (None, 56, 56, 128)       0         \n",
            "                                                                 \n",
            " block3_conv1 (Conv2D)       (None, 56, 56, 256)       295168    \n",
            "                                                                 \n",
            " block3_conv2 (Conv2D)       (None, 56, 56, 256)       590080    \n",
            "                                                                 \n",
            " block3_conv3 (Conv2D)       (None, 56, 56, 256)       590080    \n",
            "                                                                 \n",
            " block3_pool (MaxPooling2D)  (None, 28, 28, 256)       0         \n",
            "                                                                 \n",
            " block4_conv1 (Conv2D)       (None, 28, 28, 512)       1180160   \n",
            "                                                                 \n",
            " block4_conv2 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
            "                                                                 \n",
            " block4_conv3 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
            "                                                                 \n",
            " block4_pool (MaxPooling2D)  (None, 14, 14, 512)       0         \n",
            "                                                                 \n",
            " block5_conv1 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
            "                                                                 \n",
            " block5_conv2 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
            "                                                                 \n",
            " block5_conv3 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
            "                                                                 \n",
            " block5_pool (MaxPooling2D)  (None, 7, 7, 512)         0         \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 25088)             0         \n",
            "                                                                 \n",
            " fc1 (Dense)                 (None, 4096)              102764544 \n",
            "                                                                 \n",
            " fc2 (Dense)                 (None, 4096)              16781312  \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 134260544 (512.16 MB)\n",
            "Trainable params: 134260544 (512.16 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "# extracting image features for train_validate_images\n",
        "train_validate_features = extract_features(image_dataset_path, train_validate_images)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "G1lFXAGN8aqB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3a443d50-39df-4be2-fd19-78cc2bffb933"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3726730085_2468ee9220 : [[0.         0.94499123 0.89725214 ... 0.         0.33003217 0.02918297]]\n"
          ]
        }
      ],
      "source": [
        "print(\"{} : {}\".format(list(train_validate_features.keys())[0], train_validate_features[list(train_validate_features.keys())[0]] ))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "type(train_validate_features)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hk1utZXsqw_e",
        "outputId": "91c04a70-04cd-4559-e053-26a91c379c07"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "ridkWOk789xw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e0267083-0fcf-40cc-f23b-5a8af9288ec9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "8081"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "len(train_validate_features)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "37jgd_Lq9A8W"
      },
      "outputs": [],
      "source": [
        "from pickle import dump\n",
        "dump(train_validate_features, open('./train_validate_features.pkl', 'wb'))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "with open('./train_validate_features.pkl', 'rb') as f:\n",
        "    train_validate_features = pickle.load(f)"
      ],
      "metadata": {
        "id": "Kk4LibSjr0Mi"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load libraries\n",
        "import numpy as np\n",
        "from keras.models import Model, load_model\n",
        "from keras.layers import Input, Dense, Dropout, LSTM, Embedding\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.utils import to_categorical, plot_model\n",
        "from keras.layers import add\n",
        "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau"
      ],
      "metadata": {
        "id": "GbpijQtUamsZ"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# make a dictionary of image with caption for train_validate_images\n",
        "train_validate_image_caption = {}\n",
        "\n",
        "for image, caption in new_captions_dict.items():\n",
        "\n",
        "    # check whether the image is available in both train_validate_images list and train_validate_features dictionary\n",
        "    if image in train_validate_images and image in list(train_validate_features.keys()):\n",
        "\n",
        "         train_validate_image_caption.update({image : caption})\n",
        "\n",
        "len(train_validate_image_caption)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rK_-xfCBanMB",
        "outputId": "faab34d3-0f32-47ce-98bf-af5463dd0a60"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "8081"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "list(train_validate_image_caption.values())[1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "Whcv5TZabhct",
        "outputId": "c2c2ce49-2bc0-4ef3-947a-eedba261d7b7"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'startseq black dog and spotted dog are fighting endseq'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# initialise tokenizer\n",
        "tokenizer = Tokenizer()\n",
        "\n",
        "# create word count dictionary on the captions list\n",
        "tokenizer.fit_on_texts(list(train_validate_image_caption.values()))\n",
        "\n",
        "# how many words are there in the vocabulary? store the total length in vocab_len and add 1 because word_index starts with 1 not 0\n",
        "vocab_len = len(tokenizer.word_index) + 1\n",
        "\n",
        "# store the length of the maximum sentence\n",
        "max_len = max(len(train_validate_image_caption[image].split()) for image in train_validate_image_caption)\n",
        "\n",
        "def prepare_data(image_keys):\n",
        "\n",
        "    # x1 will store the image feature, x2 will store one sequence and y will store the next sequence\n",
        "    x1, x2, y = [], [], []\n",
        "\n",
        "    # iterate through all the images\n",
        "    for image in image_keys:\n",
        "\n",
        "        # store the caption of that image\n",
        "        caption = train_validate_image_caption[image]\n",
        "\n",
        "        # split the image into tokens\n",
        "        caption = caption.split()\n",
        "\n",
        "        # generate integer sequences of the\n",
        "        seq = tokenizer.texts_to_sequences([caption])[0]\n",
        "\n",
        "        length = len(seq)\n",
        "\n",
        "        for i in range(1, length):\n",
        "\n",
        "            x2_seq, y_seq = seq[:i] , seq[i]\n",
        "\n",
        "            # pad the sequences\n",
        "            x2_seq = pad_sequences([x2_seq], maxlen = max_len)[0]\n",
        "\n",
        "\n",
        "            # encode the output sequence\n",
        "            y_seq = to_categorical([y_seq], num_classes = vocab_len)[0]\n",
        "\n",
        "            x1.append( train_validate_features[image][0] )\n",
        "\n",
        "            x2.append(x2_seq)\n",
        "\n",
        "            y.append(y_seq)\n",
        "\n",
        "    return np.array(x1), np.array(x2), np.array(y)"
      ],
      "metadata": {
        "id": "jV4EZXwKbl5-"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_x1, train_x2, train_y = prepare_data( train_validate_images[0:7081] )\n",
        "validate_x1, validate_x2, validate_y = prepare_data( train_validate_images[7081:8081] )"
      ],
      "metadata": {
        "id": "VlRaWf_HbpV-"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# feature extractor model\n",
        "input_1 = Input(shape=(4096,))\n",
        "droplayer = Dropout(0.5)(input_1)\n",
        "denselayer = Dense(256, activation='relu')(droplayer)\n",
        "\n",
        "# sequence model\n",
        "input_2 = Input(shape=(max_len,))\n",
        "embedding = Embedding(vocab_len, 256, mask_zero=True)(input_2)\n",
        "droplayer_ = Dropout(0.5)(embedding)\n",
        "lstm = LSTM(256)(droplayer_)\n",
        "\n",
        "# decoder model\n",
        "decoder1 = add([denselayer, lstm])\n",
        "decoder2 = Dense(256, activation='relu')(decoder1)\n",
        "outputs = Dense(vocab_len, activation='softmax')(decoder2)\n",
        "\n",
        "# tie it together [image, seq] [word]\n",
        "model = Model(inputs=[input_1, input_2], outputs=outputs)\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
        "\n",
        "# summarize model\n",
        "print(model.summary())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CibWGeSgcGIc",
        "outputId": "853fe08a-f6ee-412e-b443-adf2fa5db286"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " input_2 (InputLayer)        [(None, 30)]                 0         []                            \n",
            "                                                                                                  \n",
            " input_1 (InputLayer)        [(None, 4096)]               0         []                            \n",
            "                                                                                                  \n",
            " embedding (Embedding)       (None, 30, 256)              1147648   ['input_2[0][0]']             \n",
            "                                                                                                  \n",
            " dropout (Dropout)           (None, 4096)                 0         ['input_1[0][0]']             \n",
            "                                                                                                  \n",
            " dropout_1 (Dropout)         (None, 30, 256)              0         ['embedding[0][0]']           \n",
            "                                                                                                  \n",
            " dense (Dense)               (None, 256)                  1048832   ['dropout[0][0]']             \n",
            "                                                                                                  \n",
            " lstm (LSTM)                 (None, 256)                  525312    ['dropout_1[0][0]']           \n",
            "                                                                                                  \n",
            " add (Add)                   (None, 256)                  0         ['dense[0][0]',               \n",
            "                                                                     'lstm[0][0]']                \n",
            "                                                                                                  \n",
            " dense_1 (Dense)             (None, 256)                  65792     ['add[0][0]']                 \n",
            "                                                                                                  \n",
            " dense_2 (Dense)             (None, 4483)                 1152131   ['dense_1[0][0]']             \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 3939715 (15.03 MB)\n",
            "Trainable params: 3939715 (15.03 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "__________________________________________________________________________________________________\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# define checkpoint callback\n",
        "filepath = './model-ep{epoch:02d}-loss{loss:.3f}-val_loss{val_loss:.3f}.h5'\n",
        "\n",
        "callbacks = [\n",
        "             ModelCheckpoint(filepath= filepath, save_best_only=True, monitor='val_loss') ]"
      ],
      "metadata": {
        "id": "l1L1-XpYcNVW"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"shape of train_x1 \", train_x1.shape)\n",
        "print(\"shape of train_x2 \", train_x2.shape)\n",
        "print(\"shape of train_y \", train_y.shape)\n",
        "print()\n",
        "print(\"shape of validate_x1 \", validate_x1.shape)\n",
        "print(\"shape of validate_x2 \", validate_x2.shape)\n",
        "print(\"shape of validate_y \", validate_y.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GmVz92RxcUb_",
        "outputId": "bf77571d-fccf-4209-97e1-885961e4058d"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "shape of train_x1  (72279, 4096)\n",
            "shape of train_x2  (72279, 30)\n",
            "shape of train_y  (72279, 4483)\n",
            "\n",
            "shape of validate_x1  (10258, 4096)\n",
            "shape of validate_x2  (10258, 30)\n",
            "shape of validate_y  (10258, 4483)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# fit model\n",
        "history = model.fit([train_x1, train_x2],\n",
        "                    train_y,\n",
        "                    verbose = 1,\n",
        "                    epochs = 20,\n",
        "                    callbacks = callbacks,\n",
        "                    validation_data=([validate_x1, validate_x2], validate_y))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Afcr39LcYOP",
        "outputId": "2f816869-ae74-4278-c2d3-8fa6532e0428"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "2259/2259 [==============================] - 279s 117ms/step - loss: 5.0524 - val_loss: 4.5224\n",
            "Epoch 2/20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2259/2259 [==============================] - 249s 110ms/step - loss: 4.1949 - val_loss: 4.3382\n",
            "Epoch 3/20\n",
            "2259/2259 [==============================] - 244s 108ms/step - loss: 3.8604 - val_loss: 4.3079\n",
            "Epoch 4/20\n",
            "2259/2259 [==============================] - 246s 109ms/step - loss: 3.6366 - val_loss: 4.3395\n",
            "Epoch 5/20\n",
            "2259/2259 [==============================] - 240s 106ms/step - loss: 3.4631 - val_loss: 4.4250\n",
            "Epoch 6/20\n",
            "2259/2259 [==============================] - 242s 107ms/step - loss: 3.3213 - val_loss: 4.5103\n",
            "Epoch 7/20\n",
            "2259/2259 [==============================] - 247s 109ms/step - loss: 3.2009 - val_loss: 4.6049\n",
            "Epoch 8/20\n",
            "2259/2259 [==============================] - 249s 110ms/step - loss: 3.0936 - val_loss: 4.7788\n",
            "Epoch 9/20\n",
            "2259/2259 [==============================] - 236s 104ms/step - loss: 3.0060 - val_loss: 4.8280\n",
            "Epoch 10/20\n",
            "2259/2259 [==============================] - 236s 105ms/step - loss: 2.9198 - val_loss: 4.9520\n",
            "Epoch 11/20\n",
            "2259/2259 [==============================] - 235s 104ms/step - loss: 2.8472 - val_loss: 5.1557\n",
            "Epoch 12/20\n",
            "2259/2259 [==============================] - 241s 107ms/step - loss: 2.7767 - val_loss: 5.2558\n",
            "Epoch 13/20\n",
            "2259/2259 [==============================] - 247s 110ms/step - loss: 2.7130 - val_loss: 5.3792\n",
            "Epoch 14/20\n",
            "2259/2259 [==============================] - 250s 111ms/step - loss: 2.6589 - val_loss: 5.4711\n",
            "Epoch 15/20\n",
            "2259/2259 [==============================] - 250s 111ms/step - loss: 2.6083 - val_loss: 5.6203\n",
            "Epoch 16/20\n",
            "2259/2259 [==============================] - 248s 110ms/step - loss: 2.5519 - val_loss: 5.7799\n",
            "Epoch 17/20\n",
            "2259/2259 [==============================] - 247s 109ms/step - loss: 2.5093 - val_loss: 5.8630\n",
            "Epoch 18/20\n",
            "2259/2259 [==============================] - 250s 110ms/step - loss: 2.4656 - val_loss: 5.9394\n",
            "Epoch 19/20\n",
            "2259/2259 [==============================] - 249s 110ms/step - loss: 2.4280 - val_loss: 6.0563\n",
            "Epoch 20/20\n",
            "2259/2259 [==============================] - 249s 110ms/step - loss: 2.3946 - val_loss: 6.2929\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# plot training loss and validation loss\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epochs')\n",
        "plt.legend(['training', 'validation'], loc='upper right')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "WT0Wa5tfcbMV",
        "outputId": "1b21a9a9-4a7c-4e2d-c3bb-4e11f95420dd"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjcAAAHHCAYAAABDUnkqAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAABneklEQVR4nO3dd3wUdf7H8dem94RASEISQiCUBAjSxACKBQyCCupZEA85BRvoiced4ulRvJ/Y8OyIp4KeBTsWBASkSJUuhCI9ISQBQirp2fn9MbAQCaElmZT38/HYR7Iz3539DMOyb77znfnaDMMwEBEREaknnKwuQERERKQqKdyIiIhIvaJwIyIiIvWKwo2IiIjUKwo3IiIiUq8o3IiIiEi9onAjIiIi9YrCjYiIiNQrCjciIiJSryjciEitt2/fPmw2GzNmzDjv1y5evBibzcbixYsrbTdjxgxsNhv79u27oBpFpPZQuBEREZF6ReFGRERE6hWFGxEREalXFG5E5KwmTJiAzWbj999/56677sLf35+goCCefvppDMMgOTmZQYMG4efnR0hICFOmTDltG4cOHeLee+8lODgYDw8POnXqxAcffHBau6ysLIYPH46/vz8BAQHcfffdZGVlVVjX9u3b+dOf/kRgYCAeHh5069aN7777rkr3/a233qJ9+/a4u7vTrFkzRo0adVo9O3fu5JZbbiEkJAQPDw/Cw8O54447yM7OdrSZP38+vXv3JiAgAB8fH9q2bcuTTz5ZpbWKiMnF6gJEpO64/fbbiYmJ4bnnnmP27Nn8+9//JjAwkGnTpnH11Vfz/PPP8/HHHzN27Fi6d+/OFVdcAUBBQQFXXnklu3btYvTo0URFRfHFF18wfPhwsrKy+Otf/wqAYRgMGjSIZcuW8cADDxATE8M333zD3XfffVotiYmJ9OrVi7CwMJ544gm8vb35/PPPGTx4MF999RU33XTTRe/vhAkTmDhxIn379uXBBx9kx44dTJ06lTVr1rB8+XJcXV0pLi4mISGBoqIiHn74YUJCQkhJSeGHH34gKysLf39/EhMTuf7664mLi2PSpEm4u7uza9culi9fftE1ikgFDBGRsxg/frwBGPfdd59jWWlpqREeHm7YbDbjueeecyzPzMw0PD09jbvvvtux7JVXXjEA46OPPnIsKy4uNuLj4w0fHx8jJyfHMAzDmDVrlgEYL7zwQrn3ufzyyw3AmD59umP5NddcY3Ts2NEoLCx0LLPb7UbPnj2N1q1bO5YtWrTIAIxFixZVuo/Tp083AGPv3r2GYRjGoUOHDDc3N+Paa681ysrKHO3eeOMNAzDef/99wzAMY8OGDQZgfPHFF2fc9n/+8x8DMA4fPlxpDSJSNXRaSkTO2YgRIxy/Ozs7061bNwzD4N5773UsDwgIoG3btuzZs8ex7McffyQkJIQhQ4Y4lrm6uvLII4+Ql5fHkiVLHO1cXFx48MEHy73Pww8/XK6Oo0eP8vPPP3PbbbeRm5vLkSNHOHLkCBkZGSQkJLBz505SUlIual8XLFhAcXExjz76KE5OJ/+pHDlyJH5+fsyePRsAf39/AObNm0d+fn6F2woICADg22+/xW63X1RdInJ2Cjcics6aN29e7rm/vz8eHh40adLktOWZmZmO5/v376d169blQgJATEyMY/2Jn6Ghofj4+JRr17Zt23LPd+3ahWEYPP300wQFBZV7jB8/HjDH+FyMEzX98b3d3Nxo2bKlY31UVBSPPfYY7777Lk2aNCEhIYE333yz3Hib22+/nV69ejFixAiCg4O54447+PzzzxV0RKqJxtyIyDlzdnY+p2Vgjp+pLidCwdixY0lISKiwTXR0dLW9/x9NmTKF4cOH8+233/LTTz/xyCOPMHnyZFatWkV4eDienp4sXbqURYsWMXv2bObOnctnn33G1VdfzU8//XTGP0MRuTDquRGRahcZGcnOnTtP66nYvn27Y/2Jn6mpqeTl5ZVrt2PHjnLPW7ZsCZintvr27Vvhw9fX96Jrrui9i4uL2bt3r2P9CR07duSpp55i6dKl/PLLL6SkpPD222871js5OXHNNdfw8ssvs3XrVv7v//6Pn3/+mUWLFl1UnSJyOoUbEal2AwYMIC0tjc8++8yxrLS0lNdffx0fHx/69OnjaFdaWsrUqVMd7crKynj99dfLba9p06ZceeWVTJs2jdTU1NPe7/Dhwxddc9++fXFzc+O1114r1wv13nvvkZ2dzcCBAwHIycmhtLS03Gs7duyIk5MTRUVFgDlG6I8uueQSAEcbEak6Oi0lItXuvvvuY9q0aQwfPpx169bRokULvvzyS5YvX84rr7zi6GW54YYb6NWrF0888QT79u0jNjaWr7/+utz4lRPefPNNevfuTceOHRk5ciQtW7YkPT2dlStXcuDAATZt2nRRNQcFBTFu3DgmTpxI//79ufHGG9mxYwdvvfUW3bt356677gLg559/ZvTo0dx66620adOG0tJS/ve//+Hs7Mwtt9wCwKRJk1i6dCkDBw4kMjKSQ4cO8dZbbxEeHk7v3r0vqk4ROZ3CjYhUO09PTxYvXswTTzzBBx98QE5ODm3btmX69OkMHz7c0c7JyYnvvvuORx99lI8++gibzcaNN97IlClT6Ny5c7ltxsbGsnbtWiZOnMiMGTPIyMigadOmdO7cmX/9619VUveECRMICgrijTfeYMyYMQQGBnLffffx7LPP4urqCkCnTp1ISEjg+++/JyUlBS8vLzp16sScOXO47LLLALjxxhvZt28f77//PkeOHKFJkyb06dOHiRMnOq62EpGqYzOqc9SfiIiISA3TmBsRERGpVxRuREREpF5RuBEREZF6ReFGRERE6hWFGxEREalXFG5ERESkXmlw97mx2+0cPHgQX19fbDab1eWIiIjIOTAMg9zcXJo1a3baJLx/1ODCzcGDB4mIiLC6DBEREbkAycnJhIeHV9qmwYWbE7d5T05Oxs/Pz+JqRERE5Fzk5OQQERFxTpPiNrhwc+JUlJ+fn8KNiIhIHXMuQ0o0oFhERETqFYUbERERqVcUbkRERKReaXBjbkREpP6w2+0UFxdbXYZUETc3t7Ne5n0uFG5ERKROKi4uZu/evdjtdqtLkSri5OREVFQUbm5uF7UdhRsREalzDMMgNTUVZ2dnIiIiquR/+2KtEzfZTU1NpXnz5hd1o12FGxERqXNKS0vJz8+nWbNmeHl5WV2OVJGgoCAOHjxIaWkprq6uF7wdRV0REalzysrKAC769IXULieO54nje6EUbkREpM7SHIH1S1UdT4UbERERqVcUbkREROqgFi1a8Morr5xz+8WLF2Oz2cjKyqq2mmoLDSgWERGpIVdeeSWXXHLJeYWSM1mzZg3e3t7n3L5nz56kpqbi7+9/0e9d2ynciIiI1BKGYVBWVoaLy9m/noOCgs5r225uboSEhFxoaeeuKBdcPcHJuoih01IiIiI1YPjw4SxZsoRXX30Vm82GzWZjxowZ2Gw25syZQ9euXXF3d2fZsmXs3r2bQYMGERwcjI+PD927d2fBggXltvfH01I2m413332Xm266CS8vL1q3bs13333nWP/H01IzZswgICCAefPmERMTg4+PD/379yc1NdXxmtLSUh555BECAgJo3Lgxjz/+OHfffTeDBw+ueCePHYGMXXB0HxjW3VxR4UZEROo8wzDILy615GEYxjnV+OqrrxIfH8/IkSNJTU0lNTWViIgIAJ544gmee+45tm3bRlxcHHl5eQwYMICFCxeyYcMG+vfvzw033EBSUlKl7zFx4kRuu+02fvvtNwYMGMDQoUM5evToGdvn5+fz0ksv8b///Y+lS5eSlJTE2LFjHeuff/55Pv74Y6ZPn87y5cvJyclh1qxZFR0AyEmB7GTzubO1J4Z0WkpEROq8gpIyYv81z5L33jopAS+3s3+d+vv74+bmhpeXl+P00Pbt2wGYNGkS/fr1c7QNDAykU6dOjufPPPMM33zzDd999x2jR48+43sMHz6cIUOGAPDss8/y2muv8euvv9K/f/8K25eUlPD222/TqlUrAEaPHs2kSZMc619//XXGjRvHTTfdBMAbb7zBjz/+WH4jdjtk7YPCbPO5bwj4hICFl+mr50ZERMRi3bp1K/c8Ly+PsWPHEhMTQ0BAAD4+Pmzbtu2sPTdxcXGO3729vfHz8+PQoUNnbO/l5eUINgChoaGO9tnZ2aSnp3PppZc61js7O9O1a9eTGygrgYydx4ONDQIiwTfU0mAD6rkREZF6wNPVma2TEix774v1x6uexo4dy/z583nppZeIjo7G09OTP/3pT2edAf2PUxbYbLZKJxatqP25nmajpACO7oGyYrA5Q2BLcPc5t9dWM4UbERGp82w22zmdGrKam5vbOU0tsHz5coYPH+44HZSXl8e+ffuqubry/P39CQ4OZs2aNVxxxRWAOS3C+vXruSSuAxzZCUYZOLubwcbVo0brq0zt/5sgIiJST7Ro0YLVq1ezb98+fHx8ztir0rp1a77++mtuuOEGbDYbTz/9dKU9MNXl4YcfZvLkyURHR9OuXTtef/11MjOPYivJN4ONq7cZbCweQPxHGnMjIiJSQ8aOHYuzszOxsbEEBQWdcQzNyy+/TKNGjejZsyc33HADCQkJdOnSpYarhccff5whQ4YwbNgw4uPj8XGFhCsuw8PdDTwaQePoWhdsAGzGOZ9cqx9ycnLw9/cnOzsbPz8/q8sREZELUFhYyN69e4mKisLDo/acDqm37HbI2o89/ygxfW7htlsG88zz/6nygcOVHdfz+f6ufXFLREREaoX9+/fz09w59OkURdGxbN6Y/jl7kw9y51/ut/yKqMoo3IiIiEiFnMqKmfHeNMZu34VhGHTo0J4FCxYQExNjdWmVUrgRERGR0xXlEuFZwPJZ74OzGwS2qlVXRFVG4UZERETKy8+ArGTAAFev41dEuZ71ZbWFwo2IiIiYDANy0yAvzXzuEWDeddipbl1crXAjIiIi5izeWUlQkGk+9wmuFVMpXAiFGxERkYaurBQy90DxMcAG/uHg3cTqqi6Ywo2IiEhDVloIGXugrMicI6pRC/Co2/eBU7gRERFpqIryzMkvjbLjV0S1BFdPq6u6aHVrhJCIiEgD1qJFC1555RXHc5vNxqxZs87Yft++fdhsNjZu3Hj6yvyjkLHr+BxRXtCkzRmDTaXbqYXUcyMiIlJHpaam0qhRo/N7kWFAXjrkpprPPfyPXxHlDMDw4cPJysoqF5oiIiJITU2lSZO6MQ5H4UZERKSOCgkJOb8XlBSYl3oXZpnPvZuCX7OzXhHl7Ox8/u9lIZ2WEhERqQHvvPMOzZo1w263l1s+aNAg7rnnHnbv3s2gQYMIDg7Gx8eH7t27s2DBgkq3+cfTUr/++iudO3fGw8ODbt26sWHDBnNFYQ4c+Z2ytETuHTWGqMuux7NVT9peejWvvvaa4/UTJkzggw8+4Ntvv8Vms2Gz2Vi8eHGFp6WWLFnCpZdeiru7O6GhoTzxxBOUlpY61l955ZU88sgj/OMf/yAwMJCQkBAmTJhwwX9+58PycJOSksJdd91F48aN8fT0pGPHjqxdu7bS1yxevJguXbrg7u5OdHQ0M2bMqJliRUSkdjIM8zJmKx6GcU4l3nrrrWRkZLBo0SLHsqNHjzJ37lyGDh1KXl4eAwYMYOHChWzYsIH+/ftzww03kJSUdE7bz8vL4/rrryc2NpZ169Yx4emnGPvYGHNlzkEoPobdbic8ojlffDaTrVu38q9//Ysnn3ySzz//HICxY8dy22230b9/f1JTU0lNTaVnz56nvVdKSgoDBgyge/fubNq0ialTp/Lee+/x73//u1y7Dz74AG9vb1avXs0LL7zApEmTmD9//jntz8Ww9LRUZmYmvXr14qqrrmLOnDkEBQWxc+fOSs8f7t27l4EDB/LAAw/w8ccfs3DhQkaMGEFoaCgJCQk1WL2IiNQaJfnwbDNr3vvJg+DmfdZmjRo14rrrruOTTz7hmmuuAeDLL7+kSZMmXHXVVTg5OdGpUydH+2eeeYZvvvmG7777jtGjR591+5988gl2u533pr6GR1ku7Ru14MD9Q3lw3LPmeBqfEFy9GzPxhUsdr4mKimLlypV8/vnn3Hbbbfj4+ODp6UlRUVGlp6HeeustIiIieOONN7DZbLRr146DBw/y+OOP869//Qun43c0jouLY/z48QC0bt2aN954g4ULF9KvX7+z7s/FsDTcPP/880RERDB9+nTHsqioqEpf8/bbbxMVFcWUKVMAiImJYdmyZfznP/9RuBERkVpt6NChjBw5krfeegt3d3c+/vhj7rjjDpycnMjLy2PChAnMnj2b1NRUSktLKSgoOLeeG8POtt82EBcTjUfeyfbxPY4HmcatwC8UgDfffJP333+fpKQkCgoKKC4u5pJLLjmv/di2bRvx8fHYThmr06tXL/Ly8jhw4ADNmzcHzHBzqtDQUA4dOnRe73UhLA033333HQkJCdx6660sWbKEsLAwHnroIUaOHHnG16xcuZK+ffuWW5aQkMCjjz5aYfuioiKKioocz3NycqqkdhERqUVcvcweFKve+xzdcMMNGIbB7Nmz6d69O7/88gv/+c9/APOU0Pz583nppZeIjo7G09OTP/3pTxQXF1e+0fyjkJ4IRTlgLwNs4NnIvMPw4eOjT2zmz5kzZzJ27FimTJlCfHw8vr6+vPjii6xevfpC9vysXF3LT7Zps9lOG3NUHSwNN3v27GHq1Kk89thjPPnkk6xZs4ZHHnkENzc37r777gpfk5aWRnBwcLllwcHB5OTkUFBQgKdn+Wv0J0+ezMSJE6ttH0REpBaw2c7p1JDVPDw8uPnmm/n444/ZtWsXbdu2pUuXLgAsX76c4cOHc9NNNwHmGJp9+/advhHDMG++d+yw+bwwC+ylxLSJ5n9fz6HQvxUe3r4ArFq1qtxLly9fTs+ePXnooYccy3bv3l2ujZubG2VlZZXuR0xMDF999RWGYTh6b5YvX46vry/h4eHn+sdRbSwdUGy32+nSpQvPPvssnTt35r777mPkyJG8/fbbVfYe48aNIzs72/FITk6usm2LiIicr6FDhzJ79mzef/99hg4d6ljeunVrvv76azZu3MimTZu48847y/dy2MvMyS3zDkHGzpOXc7t4QKMo7nxgLDYnZ0Y+8BBbt27lxx9/5KWXXir33q1bt2bt2rXMmzeP33//naeffpo1a9aUa9OiRQt+++03duzYwZEjRygpKTltHx566CGSk5N5+OGH2b59O99++y3jx4/nsccec4y3sZKlFYSGhhIbG1tuWUxMTKXnF0NCQkhPTy+3LD09HT8/v9N6bQDc3d3x8/Mr9xAREbHK1VdfTWBgIDt27ODOO+90LH/55Zdp1KgRPXv25IYbbiAhIcHs1bGXQXaKeerJXgr2EsAJvBqbL/RrBp4B+Pj68v3337N582Y6d+7MP//5T55//vly733//fdz8803c/vtt9OjRw8yMjLK9eIAjBw5krZt29KtWzeCgoJYvnz5afsQFhbGjz/+yK+//kqnTp144IEHuPfee3nqqaeq/M/rQtgM4xyvYasGd955J8nJyfzyyy+OZWPGjGH16tWsWLGiwtc8/vjj/Pjjj2zevLncdk5cTnc2OTk5+Pv7k52draAjIlJHFRYWsnfvXqKiovDw8LC6nKpnGFCUC8eOQFH2yeXObuAdBF6B4FT/7sNb2XE9n+9vS3tuxowZw6pVq3j22WfZtWsXn3zyCe+88w6jRo1ytBk3bhzDhg1zPH/ggQfYs2cP//jHP9i+fTtvvfUWn3/+OWPGjLFiF0RERKrGiXv15KbBoW1wdPfJYOPua05q2TQWfJrWy2BTlSz90+nevTvffPMN48aNY9KkSURFRfHKK6+UOweZmppa7jRVVFQUs2fPZsyYMbz66quEh4fz7rvv6jJwERGpe8pKzKucCnPNn8YpA3ltx089eTUB13rYO1WNLD0tZQWdlhIRqfvq7Gkpw272zhTmmKedSgvKr7c5g7sPuPuZl3Mfn8yyoaiq01Lq1xIREakuhgGlRWavTFEuFOeZAedUrl7maSd3P3DzctyTRi6cwo2IiNRZtfLkg73UvA/NiUBT9oeb8Dm5Hg8zxwONs76KT6iq46k/URERqXOcnc3TNcXFxRXeBqRGGYY5t1VRrnm6qeTYHxocv8Ggh58ZZlw8zJsOymlO3I35xPG9UAo3IiJS57i4uODl5cXhw4dxdXWt+RvHlRWbY2eK8s1TTfzhjr5ObubYGTdv87TTibEzZUBZ0R+3Jpg39j18+DBeXl64uFxcPFG4ERGROsdmsxEaGsrevXvZv39/zbxpWTGUFJiPP55qsjmZPTIuHuaVTU7OkFsAFFS4KamYk5MTzZs3Lzch54VQuBERkTrJzc2N1q1bn31iyQtVUggH1sK+pbBvGRw7dTZrGwTFQGQ8RFwGIR3A2fWMm5Jz4+bmViW9cAo3IiJSZzk5OVXtpeC56bBzHuyYC3sWmWNpTnD1huiroc110Ppa8AmquveVKqVwIyIiDZdhmHM2/T7HDDQpa8uv9wuDtteZgaZFb91Mr45QuBERkYaltMg8zfT7XDPQZP9hsuZmXY4Hmv4Q0lFXNtVBCjciIlL/HcuAnT+ZPTS7Fh6/wuk4Fw9oeRW07Q+tE8Av1Lo6pUoo3IiISP1jGHDkd9gxx3wc+LX8nYF9QqBNgtlDE9XHvDOw1BsKNyIiUn8YBmyfDQsnwZEd5deFdDTHzrTtD6GdoabvjSM1RuFGRETqh/StMPcJ2LvEfO7sBlFXmGNn2vSHgAhr65Mao3AjIiJ1W/5RWDwZ1rwHRhk4u0PP0dDrUXPKA2lwFG5ERKRuKiuFddNh0f9BQaa5LOYG6PcMBEZZW5tYSuFGRETqnj1LzFNQh7aaz5vGQv/J0PJKS8uS2kHhRkRE6o7MffDTU7Dte/O5ZyO46p/Q9S/grK80MelvgoiI1H5FebDsZVjxhjmrts0Zut8LV44Dr0Crq5NaRuFGRERqL8OA3z6HBeMhN9VcFtUH+j8HwbHW1ia1lsKNiIjUTinrYM4T5g34AAIiIeFZaDdQUyJIpRRuRESkdslNh4UTYePH5nNXb7jib3DZKE1cKedE4UZERGqH0iJYNRWWvgTFueayTkPgmvGa70nOi8KNiIhYyzDMGbrnPQlH95jLwrpC/+choru1tUmdpHAjIiLWObQd5o2D3T+bz32Coe8EiLtDcz/JBVO4ERGRmleQCYufh1/fOT5lghvEj4LL/wbuvlZXJ3Wcwo2IiNSc0iL49b/wy0snp0xoOxAS/g2BLa2tTeoNhRsREal+djts/gJ+/jdkJ5nLgtqZUya0utra2qTeUbgREZHqYxiweyHMnwDpm81lvqFw1ZPQ6U5NmSDVQn+rRESkehzcAPPHw94l5nN3P+g9Bno8AG5e1tYm9ZrCjYiIVK2je83TT1u+NJ87u0H3kXDFWM0DJTVC4UZERKrGsSOw9EVY8x7YSwAbxN1mztrdKNLq6qQBUbgREZGLU3wMVr0Fy149eWfhVldD34kQGmdtbdIgWXqHpAkTJmCz2co92rVrd8b2M2bMOK29h4fmGRERsURZKaydDq91MU9DFedCSBz8eRb8+RsFG7GM5T037du3Z8GCBY7nLi6Vl+Tn58eOHTscz22aGVZEpGYZBmz/ARZMhIyd5rKASLjmX9D+Zt1ZWCxnebhxcXEhJCTknNvbbLbzai8iIlUoaRXM/xckrzafewZCn39At3vAxd3a2kSOszxe79y5k2bNmtGyZUuGDh1KUlJSpe3z8vKIjIwkIiKCQYMGkZiYWGn7oqIicnJyyj1EROQ8Hd4Bn94J7yeYwcbFEy4fC3/dCJc9qGAjtYrNMAzDqjefM2cOeXl5tG3bltTUVCZOnEhKSgpbtmzB1/f0uUVWrlzJzp07iYuLIzs7m5deeomlS5eSmJhIeHh4he8xYcIEJk6ceNry7Oxs/Pz8qnyfRETqlZxUWPwsbPgIDDvYnKHLn6HPE+AXanV10oDk5OTg7+9/Tt/floabP8rKyiIyMpKXX36Ze++996ztS0pKiImJYciQITzzzDMVtikqKqKoqMjxPCcnh4iICIUbEZHKHDtiXgG18i0oLTCXtbserhkPQW2srU0apPMJN5aPuTlVQEAAbdq0YdeuXefU3tXVlc6dO1fa3t3dHXd3dZeKiJzVsSOw7XvYOgv2/mLO1g0Q0QP6TYLml1lansi5qlXhJi8vj927d/PnP//5nNqXlZWxefNmBgwYUM2ViYjUU2cKNADNOpvjatoNBF2ZKnWIpeFm7Nix3HDDDURGRnLw4EHGjx+Ps7MzQ4YMAWDYsGGEhYUxefJkACZNmsRll11GdHQ0WVlZvPjii+zfv58RI0ZYuRsiInVLZYEm9BJoPxhiB0NglDX1iVwkS8PNgQMHGDJkCBkZGQQFBdG7d29WrVpFUFAQAElJSTidcr+EzMxMRo4cSVpaGo0aNaJr166sWLGC2NhYq3ZBRKRuOJYB27+HxG8qCDSdoP1NEDsIAltaV6NIFalVA4prwvkMSBIRqdMcgWYW7F16eqCJHWz20ijQSB1QZwcUi4jIRaos0ITEneyhadzKshJFqpvCjYhIXZd/1BxDk/jNGQLNYLOXRoFGGgiFGxGRuqj4GGz5ygw0e5Yo0IicQuFGRKQuyUmFX9+Bte9DYdbJ5SEdj59yGqxAIw2ewo2ISF2QtgVWvgmbvwB7ibmsURR0vssMNQo0Ig4KNyIitZVhwK6FsPJ12LP45PLm8RA/GtpeB07OlpUnUlsp3IiI1DYlhbD5c7On5vB2c5nN2bzKKX40hHe1tj6RWk7hRkSktjiWAWvehTX/hWOHzWVuvtBlGPS4HxpFWlufSB2hcCMiYrUjO81emk2fQmmhucwvHC57wAw2Hv7W1idSxyjciIhYwTBg3zIz1Pw+5+Ty0Eug58PmKShnV8vKE6nLFG5ERGpSWYl59+CVr0PqpuMLbebg4PjRENlTM3CLXCSFGxGRmlCQBes/gNXTICfFXObiCZfcCZc9BE2iLS1PpD5RuBERqU6Z+2H127D+QyjOM5d5N4VL74Nu94B3Y2vrE6mHFG5ERKpaWYl5f5qNH8P2H8Cwm8ubxkL8KOh4K7i4W1ujSD2mcCMiUhUMA1LWw28zzTmf8jNOrmt1tTmeptXVGk8jUgMUbkRELkbmfvOGe5s+g4ydJ5d7NzV7aDrfBcGx1tUn0gAp3IiInK+CLNj6Lfz2GexffnK5iyfEXA9xd0DLK8FZ/8SKWEGfPBGRc1FWArsWwKaZsGMOlBUdX2GDqCug0x0QcwO4+1papogo3IiInFll42iaxkLc7eapJ/8w62oUkdMo3IiI/FHmfvjtczPUZOw6udy7KcTdZoaakI4aHCxSSynciIjA8XE0s8yBwUkrTi539YJ215uBRuNoROoEfUpFpOEqK4Gd880emh1zNY5GpJ5QuBGRhiltM3x5Dxz5/eQyjaMRqRcUbkSkYTEMWPsezH3S7KnxagydhmgcjUg9onAjIg1HQRZ8/4h5jxqA1gkweKrmdxKpZxRuRKRhOLAOvhwOWUng5Ap9J5jzPKmnRqTeUbgRkfrNbodVb8KCCWAvhYBI+NN0CO9qdWUiUk0UbkSk/jqWAbMehJ3zzOexg+DG18HD39q6RKRaKdyISP20bzl8NQJyD4KzO/SfDN3u0WkokQZA4UZE6hd7GfwyBRZPBsMOjVvDrdPNK6FEpEFQuKlCuw7lkZlfTPcWgVaXItIw5abB1yNh71Lzeac7YcCL4O5jbV0iUqMUbqrID78dZPQnG4gN9ePHv15udTkiDc+uBfD1/ZB/BFy9YeAUuGSI1VWJiAWcrHzzCRMmYLPZyj3atWtX6Wu++OIL2rVrh4eHBx07duTHH3+soWor17NVE5xssDU1h6SMfKvLEWk4ykrMK6E+usUMNsEd4L7FCjYiDZil4Qagffv2pKamOh7Lli07Y9sVK1YwZMgQ7r33XjZs2MDgwYMZPHgwW7ZsqcGKKxbo7UaPKPNGYPMS0yyuRqSByEqC6QNg2X/M593uhRELIKiNtXWJiKUsDzcuLi6EhIQ4Hk2aNDlj21dffZX+/fvz97//nZiYGJ555hm6dOnCG2+8UYMVn1n/DiEAzFW4Eal+22fD25fDgV/B3Q9u/QCufxlcPa2uTEQsZnm42blzJ82aNaNly5YMHTqUpKSkM7ZduXIlffv2LbcsISGBlStXnvE1RUVF5OTklHtUl4T2ZrhZtz+TQzmF1fY+Ig1aaRHMeRxm3gmFWRDWFR74BdoPtroyEaklLA03PXr0YMaMGcydO5epU6eyd+9eLr/8cnJzcytsn5aWRnBwcLllwcHBpKWduadk8uTJ+Pv7Ox4RERFVug+nCvH3oHPzAECnpkSqRcZueK8frH7bfB4/Gv4yFxq1sLQsEaldLA031113HbfeeitxcXEkJCTw448/kpWVxeeff15l7zFu3Diys7Mdj+Tk5CrbdkX6t9epKZFqsflLmNYHUjeBZyDc+Tkk/B+4uFldmYjUMpafljpVQEAAbdq0YdeuXRWuDwkJIT09vdyy9PR0QkJCzrhNd3d3/Pz8yj2q04lTU6v2HCXzWHG1vpdIg1CcD989DF/dC8W50LwnPLAM2iRYXZmI1FK1Ktzk5eWxe/duQkNDK1wfHx/PwoULyy2bP38+8fHxNVHeOWnRxJt2Ib6U2Q0WbEs/+wtEpGKGAftXwH+vhvUfAja44h9w9/fgH2Z1dSJSi1kabsaOHcuSJUvYt28fK1as4KabbsLZ2ZkhQ8z7UwwbNoxx48Y52v/1r39l7ty5TJkyhe3btzNhwgTWrl3L6NGjrdqFCl3XwQxnGncjcgHKSmHL12aomX4dHN4GPsEwbBZc/U9w1r1HRaRylv4rceDAAYYMGUJGRgZBQUH07t2bVatWERQUBEBSUhJOTifzV8+ePfnkk0946qmnePLJJ2ndujWzZs2iQ4cOVu1Chfp3COE/C35n6c4j5BWV4uOuf4xFzqooF9b/D1ZNhezjV006u0OnO+Dqp8CnqbX1iUidYTMMw7C6iJqUk5ODv78/2dnZ1Tb+xjAMrp6yhL1HjvH6kM7c0KlZtbyPSL2QnQK/ToO1M6Ao21zm1Ri6j4TuI8AnyNLyRKR2OJ/vb3UpVAObzUZC+xDeXrKbuYlpCjciFUn9DVa+AVu+AnupuaxxNMSPgk5DdDM+EblgCjfVpH8HM9ws2n6IwpIyPFydrS5JxHqGYU5wueJ12Lvk5PLI3tBzNLROAKdadZ2DiNRBCjfVpFO4P6H+HqRmF7Js5xH6xgaf/UUi9VVJIWz+HFa+CYe3m8tszuZdheNHQ1gXS8sTkfpF4aaanDg1NWPFPuYmpincSMOUfxTWvAe/vgPHDpnL3Hyh693Q434IaG5tfSJSLyncVKP+HcxwM39rOiVldlyd1d0uDUTGbrOXZuMnUFpgLvMLgx4PmMHGw9/a+kSkXlO4qUbdWwTS2NuNjGPFrN5zlN6tzzzjuUidZxiQtMocJLx9NnD8QsyQOOj5iHkKytnVygpFpIFQuKlGzk42+sUGM3NNMnMTUxVupH4qK4Xt38OKNyBl7cnlrRPMQcItLgebzbr6RKTBUbipZv07hDBzTTLzEtOZdGMHnJz0j7zUYXa7eYO99MTjjy1wYC3kpJjrT9x0L34UBLW1tlYRabAUbqpZz1ZN8HV34XBuERuSM+kaGWh1SSLnpiALDm09Jcgkms+L805v69XYvOFe9xG6k7CIWE7hppq5uThxTUxTZm08yJzNaQo3UvuUlULGLrMX5tQwk51ccXtnNwhqB8HtzUfTWIjsqZvuiUitoXBTA/p3CGHWxoPMTUzjnwNjsGn8gVgl75AZYtITIX2r+fvhHVBWVHF7/4iTASa4PQR3gMatNDBYRGo1hZsacEWbIDxcnTiQWUDiwRw6hOkyWKkhJQWw6i3Yu9QMNMcOV9zOzeeUAHNKj4xnQI2WKyJSFRRuaoCXmwtXtmnK3MQ05iWmKdxIzdi9CH4YA5l7Ty6zOUFgKwiONXthTgQZ/+aa9kBE6g2FmxrSv0MIcxPTmLsljb9dq6tIpBodOwLz/gm/zTSf+zaDK/4GzbqYY2XcvKytT0Skminc1JCr2jXF1dnGzkN57DqUR3RTH6tLkvrGMGDTTJj3JBQcBWxw6X1w9VPg4Wd1dSIiNUb90DXE39OVnq3Mm/jNS0yzuBqpdzJ2w4eDYNYDZrAJ7gAjFsCAFxRsRKTBUbipQf07hAAwd4vCjVSRshL4ZQpM7Ql7l4CLB/SdAPcthvBuVlcnImIJhZsa1C82GCcbbE7J5kBmvtXlSF2XvAamXQELJ0FpIbS8Ch5aCb3H6FJtEWnQFG5qUBMfd7q3MG/iNy8x3eJqpM4qzIHZY+G9fuZN97waw03vwJ+/gcCWVlcnImI5hZsadvLUVKrFlUidtO17ePNSWPNfwIBOd8KoNdDpdk1OKSJynMJNDUtob4abtfszOZRbaHE1Umdkp8DMofDZXZCbavbQDPsWbpoK3o2trk5EpFZRuKlhzQI86RTuj2HA/K06NSVnYS+D1e/Amz1g+w/g5AKXj4UHV0DLK62uTkSkVlK4sUD/DqGArpqSs0jbAu9dC3P+DsW5EN4d7v8Frnlak1SKiFRC4cYCCe2DAVi5O4Ps/BKLq5Fap6QAFkyAd/pAylpw84UBL8E9P5nTJoiISKUUbizQMsiHtsG+lNoNFmzTqSk5xe5F8FY8LPsP2Esh5gYY/StcOlJzP4mInCP9a2mRhBNXTeluxQLmfFBf3w//G2xOdOnbDG7/GG7/CPyaWV2diEidonBjkf7Hr5pa+vthjhWVWlyNWCY7BZa/Bm90Pz7RpQ0uvR9GrYaY662uTkSkTtLEmRaJCfUlsrEX+zPyWfL7YQZ0DLW6JKkpeYdh6yzY8jUkrTi5vGl7uPE1TZsgInKRFG4sYrPZ6N8+hGlL9zB3S5rCTX1XkAnbfoAtX5lzQBn2k+uax0PHW6HLME2bICJSBRRuLJTQwQw3P28/RFFpGe4uzlaXJFWpKBd2zDUDza4FYD/lyrhmnaHDLdD+JvAPt65GEZF6SOHGQpeEBxDs5056ThHLdx3h6nbBVpckF6ukAHb+ZAaa3+eZE1qe0LQ9dLjZDDSNW1lXo4hIPadwYyEnJxsJ7UP4cOV+5m5JU7ipq0qLYc8iM9Bsnw3FeSfXBbaEDn8yQ03TGOtqFBFpQGrN1VLPPfccNpuNRx999IxtZsyYgc1mK/fw8PCouSKrwYmJNOdvTae0zH6W1lJr2Mtgz2L47mF4qTV8chv89pkZbPwjoOcjcN8SeHg9XP1PBRsRkRpUK3pu1qxZw7Rp04iLiztrWz8/P3bs2OF4bqstMyHb7fDNfRB3O7Tud84vu7RFII28XMnML+HXfUfp2apJNRYpF8VuhwO/mj00ibPg2KGT63yCzdNN7W82p0nQDfdERCxjebjJy8tj6NCh/Pe//+Xf//73WdvbbDZCQkJqoLLztOkT2PyF+eh8FyQ8Cx7+Z32Zi7MT/WKD+XztAeZuSVO4qW3sdjiwBrZ9ZwaanAMn13k2gthB5sDgyF7gpAHhIiK1geX/vRw1ahQDBw6kb9++59Q+Ly+PyMhIIiIiGDRoEImJiZW2LyoqIicnp9yjWrS/GS4bBdhgw0fmLfR3LTinl544NTUvMQ273aie+uTclRSYVzl99zBMaQPvXwsr3zCDjZsvdBoCQ7+EsTvhhlch6goFGxGRWsTSnpuZM2eyfv161qxZc07t27Zty/vvv09cXBzZ2dm89NJL9OzZk8TERMLDK76cdvLkyUycOLEqy66Ymxf0f9acC+jbh+DoHvjoFvPeJdf+H3j4nfGlvaKb4OPuQnpOERsPZNGleaPqr1fKyz9qXt20YzbsWggl+SfXufubpxrbD4bofuBat8d5iYjUdzbDMCzpKkhOTqZbt27Mnz/fMdbmyiuv5JJLLuGVV145p22UlJQQExPDkCFDeOaZZypsU1RURFFRkeN5Tk4OERERZGdn4+d35sBxUYrzYeEkWP02YIBfOAx6HVpdfcaXPPLpBr7bdJD7r2jJuAEafFojMvfB9h/NK5ySVoJRdnKdXxi0HQDtBkBkb3Bxs6xMERExv7/9/f3P6fvbsnAza9YsbrrpJpydT3bnl5WVYbPZcHJyoqioqNy6M7n11ltxcXHh008/Paf3PZ8/nIu2b7nZi5O5z3zedTj0e6bCXpwfN6fy0MfriWzsxeKxV9aegdL1iWFA6kYzzGz/EQ794ZRmcIeTgSb0EtAxEBGpNc7n+9uy01LXXHMNmzdvLrfsL3/5C+3atePxxx8/p2BTVlbG5s2bGTBgQHWVeXFa9IIHV8CCifDrNFg3wzzlcePr0Oqqck37tAnC3cWJ/Rn5bEvNJbZZNQevhqK0GPb9Ajt+hB1zICfl5DqbM0T2PBloGrWwrEwREak6FxRuPvjgA5o0acLAgQMB+Mc//sE777xDbGwsn376KZGRkWfdhq+vLx06dCi3zNvbm8aNGzuWDxs2jLCwMCZPngzApEmTuOyyy4iOjiYrK4sXX3yR/fv3M2LEiAvZjZrh5g0DXjg+FmcUZO2H/w2GbvdAv0ng7guAt7sLV7QJYv7WdOYmpincXIzCbNg53ww0O+dD0SmDyF29IfpqaDsQ2iSAV6B1dYqISLW4oKulnn32WTw9PQFYuXIlb775Ji+88AJNmjRhzJgxVVZcUlISqampjueZmZmMHDmSmJgYBgwYQE5ODitWrCA2NrbK3rPaRF1u9uJ0H2k+X/s+vNUT9ixxNLnuxFVTW9KsqLBuy06BX/8L/7sJXmgFX91r3o+mKAe8m5oDu+/8HP6xB27/CC4ZomAjIlJPXdCYGy8vL7Zv307z5s15/PHHSU1N5cMPPyQxMZErr7ySw4cPV0etVaJGx9ycyd6lx3txkszn3UdA34lkl7nT9d/zKbUb/Py3PrQM8rGmvrrAMODQNvPqpu2z4eCG8usbtzZPNbW7HsK66aZ6IiJ1XLWPufHx8SEjI4PmzZvz008/8dhjjwHg4eFBQUHBhWyyYYm6Ah5cCfP/BWvfgzXvws75+A96k/hWjfll5xHmJabz4JUKN+XYyyB59fEBwbMhc+8pK23mnYHbDTBPOQW1saxMERGx1gWFm379+jFixAg6d+7M77//7hjQm5iYSIsWLaqyvvrL3Qeuf9m8w+23o82xOB9cz1PN7+AmrmXullQevFIzR1Ocb87htH02/D4H8jNOrnN2h5ZXQruB0PY68GlqVZUiIlKLXFC4efPNN3nqqadITk7mq6++onHjxgCsW7eOIUOGVGmB9V7LPvDQiuO9OO/TNmkmc90X8veUB0jJ6kpYgKfVFda8Yxnw+1xzQPCuhVB6Sm+gR4A5ELjdQGh1jRkSRURETmHZfW6sUivG3JzJ7kXmLf+zkwHYGjGE2D9PMa+4qu+O7jXDzPYfIWkFGKfMkO4fcbx3ZoB56bazq3V1ioiIJar9Jn5z587Fx8eH3r17A2ZPzn//+19iY2N58803adSo9k4fUKvDDUBhDtv/9yjtUr4ynzeKgsFvmV/q9YlhQOqmk+NnTruhXkcz0LQbACFxuqGeiEgDV+3hpmPHjjz//PMMGDCAzZs30717dx577DEWLVpEu3btmD59+gUXX91qfbgBDmTmM+7FV3ne9b80s2UANujxAFzzL3MOq7qqrAT2LTvZQ3PqDNsnbqh3ooem0dnvlSQiIg1HtV8ttXfvXse9Zb766iuuv/56nn32WdavX1977xZch4Q38iIr9HISUqL5pvUcopO/gtVTYec884vfLwz8mpk//cPAJ7j2zEpdWgy5B837zmQfMANM9vFH8mrzBnsnuHpB9DW6oZ6IiFSpCwo3bm5u5OebsyYvWLCAYcOGARAYGEhOTk5lL5Vz1L9DCC+mZPOM7QE+uOtO+O4Rc6bxlW+c3tjmDL4hxwNPM3OiTsfvx4OQbyg4X+RsG3Y7HDtkBhdHaEkxxwjlpJi/56UDlXQGegdBm/7m/Wda9gHXBjhgWkREqtUFfdv17t2bxx57jF69evHrr7/y2WefAfD7778THh5epQU2VP07hPDivB2s2H2E7CH98H9oJfz2uTkJZ04K5Bw8+TDKji9LOfMGbU5mD0+50BNWPgC5+x7fZsrJ3pYToSU72VxnLzl78c7uZo+SX5g5GPjE701jIbxb7ellEhGReumCws0bb7zBQw89xJdffsnUqVMJCwsDYM6cOfTv379KC2yoWgX50LqpDzsP5bFo+yEGdw6DS0ee3tBeBscOH+9NSTkZThw/UyAn1QwluanmI2XdhRdmczJ7gU6cEvMPN3uK/MOPh5hw8G6iAcAiImIZXQpei035aQev/7yL/u1DePvPXS98Q3Y75B852QtTLgCd8ntZEXgGHg8qxx9+YeV/r4rTWyIiIuep2gcUA5SVlTFr1iy2bdsGQPv27bnxxhtxdtYph6qS0D6E13/exeLfD5FfXIqX2wUeLicn8+69Pk2hWeeK2xgGlBWDi/uFFywiIlILXNC35a5duxgwYAApKSm0bdsWgMmTJxMREcHs2bNp1UrTBlSF9s38CG/kyYHMApb+fpj+HUKr781sNgUbERGpFy5oquRHHnmEVq1akZyczPr161m/fj1JSUlERUXxyCOPVHWNDZbNZuO6DiEAzN2SZnE1IiIidcMFhZslS5bwwgsvEBh48r4kjRs35rnnnmPJkiVVVpyYV00BLNx2iOJS+1lai4iIyAWFG3d3d3Jzc09bnpeXh5ub20UXJSd1jmhEkK87uUWlrNh9xOpyREREar0LCjfXX3899913H6tXr8YwDAzDYNWqVTzwwAPceOONVV1jg+bkZCOhfTCgU1MiIiLn4oLCzWuvvUarVq2Ij4/Hw8MDDw8PevbsSXR0NK+88koVlyj925sDiX/amk6ZvUFduS8iInLeLuhqqYCAAL799lt27drluBQ8JiaG6OjoKi1OTD1aBhLg5crRY8Ws2XeUy1o2trokERGRWuucw81jjz1W6fpFixY5fn/55ZcvvCI5jauzE31jgvly3QGmLdnNpS0CcXLSHYBFREQqcs7hZsOGDefUzqbb7leLv/RqwXebDrJox2Fe+mkH/+jfzuqSREREaiVNv1CHfLPhAGM+2wTAq3dcwqBLwiyuSEREpGacz/f3BQ0oFmvc1Dmc+/u0BOAfX/7GpuQsawsSERGphRRu6ph/JLTj6nZNKSq1c9//1pKeU2h1SSIiIrWKwk0d4+xk49U7LqF1Ux/Sc4q473/rKCwps7osERGRWkPhpg7y9XDl3bu74e/pyqbkLMZ9vZkGNnRKRETkjBRu6qjIxt5MHdoFZycb32xIYdrSPVaXJCIiUiso3NRhPaObMP6GWACen7udn7enW1yRiIiI9RRu6rg/XxbJnT2aYxjwyKcb2Zl++oSmIiIiDYnCTR1ns9mYcEN7Lo0KJK+olBEfriXzWLHVZYmIiFhG4aYecHNx4u27uhLeyJP9GfmM+mQ9JWV2q8sSERGxhMJNPRHo7ca7d3fD282ZFbsz+PcPW60uSURExBK1Jtw899xz2Gw2Hn300UrbffHFF7Rr1w4PDw86duzIjz/+WDMF1gHtQvz4z+2XAPDByv18sjrJ2oJEREQsUCvCzZo1a5g2bRpxcXGVtluxYgVDhgzh3nvvZcOGDQwePJjBgwezZcuWGqq09ru2fQhjr20DwL++3cKqPRkWVyQiIlKzLA83eXl5DB06lP/+9780atSo0ravvvoq/fv35+9//zsxMTE888wzdOnShTfeeKOGqq0bRl0VzQ2dmlFqN3jwo3UkH823uiQREZEaY3m4GTVqFAMHDqRv375nbbty5crT2iUkJLBy5crqKq9OstlsvHBLHB3D/MnML2Hkh2vJKyq1uiwREZEaYWm4mTlzJuvXr2fy5Mnn1D4tLY3g4OByy4KDg0lLSzvja4qKisjJySn3aAg83Zx5Z1hXgnzd2Z6Wy5jPNmK3a4oGERGp/ywLN8nJyfz1r3/l448/xsPDo9reZ/Lkyfj7+zseERER1fZetU2ovyfT/twVNxcn5m9N5z8Lfre6JBERkWpnWbhZt24dhw4dokuXLri4uODi4sKSJUt47bXXcHFxoazs9JmuQ0JCSE8vP8VAeno6ISEhZ3yfcePGkZ2d7XgkJydX+b7UZl2aN+K5mzsC8PrPu/h+00GLKxIREaleloWba665hs2bN7Nx40bHo1u3bgwdOpSNGzfi7Ox82mvi4+NZuHBhuWXz588nPj7+jO/j7u6On59fuUdDc3OXcO6/oiUAY7/YxOYD2RZXJCIiUn1crHpjX19fOnToUG6Zt7c3jRs3diwfNmwYYWFhjjE5f/3rX+nTpw9Tpkxh4MCBzJw5k7Vr1/LOO+/UeP11zT/6t+P39FwW7TjMyA/X8t3DvWjqW32nA0VERKxi+dVSlUlKSiI1NdXxvGfPnnzyySe88847dOrUiS+//JJZs2adFpLkdM5ONl4d0pnopj6k5RRy///WUVhy+qk/ERGRus5mGEaDuoQmJycHf39/srOzG+Qpqn1HjjHozeVkF5Rwc5cwptzaCZvNZnVZIiIilTqf7+9a3XMjVa9FE2/evLMLzk42vl6fwru/7LW6JBERkSqlcNMA9W7dhKcHxgAwec42Fu04ZHFFIiIiVUfhpoG6u2cLhlwagd2ARz7ZwK5DuVaXJCIiUiUUbhoom83GxBs7cGmLQHKLShnxwVqy8outLktEROSiKdw0YG4uTky9qwthAZ7sy8hn9CcbKC61W12WiIjIRVG4aeAa+7jz7t3d8HJzZtmuI9z13mqO5BVZXZaIiMgFU7gRYkL9ePuurvi4u/Dr3qMMemM5W1J0F2MREambFG4EgCvaBDFrVE+imniTklXAn95eoXmoRESkTlK4EYfopr7MGtWLPm2CKCyx8/CnG3hh7nbK7A3qPo8iIlLHKdxIOf6errw/vDv39zEn2nxr8W5GfriWnMISiysTERE5Nwo3chpnJxvjrovh1Tsuwd3FiZ+3H2Lwm8vZczjP6tJERETOSuFGzmjQJWF8+UBPQv092HPYnJNKdzMWEZHaTuFGKtUx3J/vRvemW2QjcgtLuWfGGt5espsGNt+qiIjUIQo3clZBvu58MvIyhlwagWHAc3O289eZGykoLrO6NBERkdMo3Mg5cXNx4tmbOvLM4A64ONn4btNBbp22gpSsAqtLExERKUfhRs6ZzWbjz5dF8tGIHgR6u7ElJYdBbyxjzb6jVpcmIiLioHAj5+2ylo35bnQvYkL9OJJXzJ3/XcUnq5OsLktERARQuJELFN7Ii68ejGdgXCglZQZPfrOZp2Zt1sSbIiJiOYUbuWBebi68MaQzf09oi80GH61K0sSbIiJiOYUbuSg2m41RV0Xz7rBumnhTRERqBYUbqRLXxARr4k0REakVFG6kykQ39WXWQ724QhNvioiIhRRupEr5e7kyfXh37r9CE2+KiIg1FG6kyjk72Rg3IIZXbtfEmyIiUvMUbqTaDO5cfuLN619fxvvL9uo0lYiIVCuFG6lWJybe7BEVSH5xGZN+2MpNb+lqKhERqT4KN1Ltgnzd+XTkZTx7U0d8PVz47UA2g95czrM/biO/uNTq8kREpJ5RuJEa4eRk484ezVn4WB8GxoVSZjd4Z+kerv3PUhbvOGR1eSIiUo8o3EiNaurnwZt3duH94d0IC/DkQGYBw6ev4eFPN3A4V3c2FhGRi6dwI5a4ul0wP425ghG9o3CywfebDnLNlMXM/DUJuwYci4jIRVC4Ect4u7vw1PWxfDuqNx3C/MgpLOWJrzdzxzur2HUo1+ryRESkjlK4Ect1DPdn1kO9eGpgDF5uzvy67yjXvfoL/5n/O0WlZVaXJyIidYyl4Wbq1KnExcXh5+eHn58f8fHxzJkz54ztZ8yYgc1mK/fw8PCowYqlurg4OzHi8pb8NOYKrm7XlJIyg1cX7uS6V39h1Z4Mq8sTEZE6xNJwEx4eznPPPce6detYu3YtV199NYMGDSIxMfGMr/Hz8yM1NdXx2L9/fw1WLNUtvJEX793djTfv7EKQrzt7Dh/jjndW8Y8vN5GVX2x1eSIiUgfYDMOoVaM3AwMDefHFF7n33ntPWzdjxgweffRRsrKyLnj7OTk5+Pv7k52djZ+f30VUKtUtu6CE5+du55PVSQA08XHj6etjubFTM2w2m8XViYhITTqf7+9aM+amrKyMmTNncuzYMeLj48/YLi8vj8jISCIiIs7ayyN1m7+nK8/e1JEvH4indVMfjuQV89eZG7l7+hqSj+ZbXZ6IiNRSlvfcbN68mfj4eAoLC/Hx8eGTTz5hwIABFbZduXIlO3fuJC4ujuzsbF566SWWLl1KYmIi4eHhFb6mqKiIoqKT90/JyckhIiJCPTd1THGpnXeW7ua1n3dRXGrHw9WJMX3bcE/vKFyda01GFxGRanI+PTeWh5vi4mKSkpLIzs7myy+/5N1332XJkiXExsae9bUlJSXExMQwZMgQnnnmmQrbTJgwgYkTJ562XOGmbtpzOI9/frOFlccHGceE+jH55o5cEhFgbWEiIlKt6lS4+aO+ffvSqlUrpk2bdk7tb731VlxcXPj0008rXK+em/rHMAy+XHeA//txG1n5JdhscHd8C/52bRt8PVytLk9ERKpBnRxzc4Ldbi8XRipTVlbG5s2bCQ0NPWMbd3d3x6XmJx5St9lsNm7tFsHCx/pwc+cwDANmrNhHnxcX89+leygs0b1xREQaMkvDzbhx41i6dCn79u1j8+bNjBs3jsWLFzN06FAAhg0bxrhx4xztJ02axE8//cSePXtYv349d911F/v372fEiBFW7YJYqLGPOy/ffgn/u/dSWjbx5uixYv7vx21c8cIiPlixTzcAFBFpoFysfPNDhw4xbNgwUlNT8ff3Jy4ujnnz5tGvXz8AkpKScHI6mb8yMzMZOXIkaWlpNGrUiK5du7JixYpzGp8j9dflrYP4acwVfL0hhVcX7CQlq4Dx3yUybcluHrmmNbd0DdegYxGRBqTWjbmpbrrPTf1WXGrns7XJvPHzTtJzzNObkY29eLRva27sFIazk+6PIyJSF9XpAcXVTeGmYSgsKePj1UlMXbyLI3nmnY2jm/owpm8brusQgpNCjohInaJwUwmFm4blWFEpH6zcx7Qle8guKAHMy8f/1q8N18Q01Z2ORUTqCIWbSijcNEw5hSW8v2wv7/6yl7yiUgA6RQQw9to29I5uopAjIlLLKdxUQuGmYcs8Vsw7v+xhxvJ9FBy/ZPzSqED+1q8NPVo2trg6ERE5E4WbSijcCMDh3CKmLt7NR6v3U1xqB+Dy1k14rF8bOjdvZHF1IiLyRwo3lVC4kVOlZhfw5qJdzPw1mVK7+VHoG9OUMf3a0L6Zv8XViYjICQo3lVC4kYokH83ntYU7+Wr9AY5nHAZ0DGFM3za0Dva1tjgREVG4qYzCjVRm9+E8Xl2wk+9/O4hhgM0Ggy8J46/XtKZFE2+ryxMRabAUbiqhcCPnYntaDv+Z/zvzEtMBcHayMaBjKPf0aqExOSIiFlC4qYTCjZyPzQeyeXn+DhbtOOxY1rl5APf0iqJ/hxBN6yAiUkMUbiqhcCMXYktKNtOX7+P7TQcpLjOvrgr192BYfAuGXBpBgJebxRWKiNRvCjeVULiRi3Eot5CPVyXx8er9jmkdPFyduKVLOH/p1YLophp8LCJSHRRuKqFwI1WhqLSM7zel8t6yvWxLzXEs79MmiHt6R3FFa931WESkKincVELhRqqSYRis3nuU95ftZf62dE58mqKb+vCXXi24uXM4nm7O1hYpIlIPKNxUQuFGqktSRj4zVuzj87XJjvmr/D1dubNHc4bFRxLq72lxhSIidZfCTSUUbqS65RaW8MXaA8xYsY+ko/nAyUvJ/9KrBV10KbmIyHlTuKmEwo3UlDK7wcJt6by/fC+r9hx1LL8kIoB7ekdxnS4lFxE5Zwo3lVC4ESskHjQvJf9u48lLyUP8PBjWM5Ih3ZvTyFuXkouIVEbhphIKN2Klw7lFfLx6Px+tKn8p+U2dw7nz0uZ0CPPTVVYiIhVQuKmEwo3UBkWlZfxw/FLyradcSh4b6scdl0YwqFMY/l6uFlYoIlK7KNxUQuFGapMTl5J/sjqJuVvSHKes3F2cuK5DCLd3b85lLQPVmyMiDZ7CTSUUbqS2yjxWzKyNKXy2JpntabmO5S0ae3Fb9wj+1CWcpn4eFlYoImIdhZtKKNxIbWcYBr8dyGbmmmS+25jCseIywLyc/Kq2TbmjewRXtg3CRVdaiUgDonBTCYUbqUuOFZUye3Mqn69JZu3+TMfypr7u3NotnNu6RRDZ2NvCCkVEaobCTSUUbqSu2nUol8/WJPPV+hSOHit2LO/ZqjG3d48goX0IHq6a6kFE6ieFm0oo3EhdV1xqZ8G2dGauSeaXnYcd81n5e7pyU+cwbu8eQUyo/m6LSP2icFMJhRupT1KyCvhibTJfrD1ASlaBY3mncH9u6x7BjZ2a4euhS8pFpO5TuKmEwo3UR2V2g2W7jvDZmiTmb02npMz8WHu6OjMwLpRbuoRzaVQgzk66pFxE6iaFm0oo3Eh9l5FXxDcbUpi5Jpldh/IcywO93egXE0xCh2B6RTfB3UXjc0Sk7lC4qYTCjTQUhmGwPimTz9Yk89PWdLLySxzrfNxduLJtEP07hHBl26b4uLtYWKmIyNkp3FRC4UYaopIyO7/uPcq8xDR+SkwnLafQsc7NxYne0U3o3z6EvrHBBGoSTxGphRRuKqFwIw2d3W6w6UAW8xLTmZeYxt4jxxzrnGxwaVQgCe1DSGgfQrMATwsrFRE56Xy+vy29xenUqVOJi4vDz88PPz8/4uPjmTNnTqWv+eKLL2jXrh0eHh507NiRH3/8sYaqFakfnJxsdG7eiCeua8fPf+vDT2Ou4LF+bWjfzA+7Aav2HGXi91vp+dzP3PjGMt5ctKvc2B0RkdrO0p6b77//HmdnZ1q3bo1hGHzwwQe8+OKLbNiwgfbt25/WfsWKFVxxxRVMnjyZ66+/nk8++YTnn3+e9evX06FDh3N6T/XciJxZ8tF85iWmMS8xjbX7Mzn1X4fopj4ktA+mf/tQOoT5aTJPEalRdfq0VGBgIC+++CL33nvvaetuv/12jh07xg8//OBYdtlll3HJJZfw9ttvn9P2FW5Ezs3h3CLmbzVPXa3YfcRxeTlAWIAn/WKD6d8hhO4tdIm5iFS/8/n+rjWXSJSVlfHFF19w7Ngx4uPjK2yzcuVKHnvssXLLEhISmDVrVg1UKNKwBPm6c2eP5tzZozk5hSUs2n6IeYlpLNp+mJSsAmas2MeMFfsI9Hajb0xTro0NoXfrJpoCQkQsZ3m42bx5M/Hx8RQWFuLj48M333xDbGxshW3T0tIIDg4utyw4OJi0tLQzbr+oqIiioiLH85ycnKopXKQB8fNwZdAlYQy6JIzCkjJ+2XmEuVvSWLg9naPHivl87QE+X3sALzdn+rQJ4tr2wVzdNhh/L90dWURqnuXhpm3btmzcuJHs7Gy+/PJL7r77bpYsWXLGgHO+Jk+ezMSJE6tkWyICHq7O9IsNpl9ssOMS8/lb0/kpMY2D2YXM2ZLGnC1pODvZuKxlINfGhtAvNlhXXolIjal1Y2769u1Lq1atmDZt2mnrmjdvzmOPPcajjz7qWDZ+/HhmzZrFpk2bKtxeRT03ERERGnMjUsUMw2BLSg4/bTXvpbMjPbfc+o5h/lwbG8y17UNoE+yjAckicl7q5JibE+x2e7kwcqr4+HgWLlxYLtzMnz//jGN0ANzd3XF3d6/qMkXkD2w2Gx3D/ekY7s/frm3LviPHzB6dreaVV5tTstmcks2U+b8T2diLa2ODSWgfQufmjTQgWUSqlKU9N+PGjeO6666jefPm5ObmOi7tnjdvHv369WPYsGGEhYUxefJkwLwUvE+fPjz33HMMHDiQmTNn8uyzz+pScJFa7nBuET9vT2deYjrLdh2huNTuWNfEx42+McFc2z6Ynq00IFlEKlZnem4OHTrEsGHDSE1Nxd/fn7i4OEewAUhKSsLJ6eR9Bnv27Mknn3zCU089xZNPPknr1q2ZNWvWOQcbEbFGkK87t3dvzu3dm5NXVMrS3w/zU2IaC7cf4kheMTPXJDNzTTJebs5c2TaIa2NDuKpdU/w9NSBZRM5frRtzU93UcyNSe5SU2Vm956hjnM6pc165ONmIb9WYfrHBXN46iBaNvTROR6QBq9M38atuCjcitZNhGGxOyeanRHOczu/p5ad8CAvwpFd0Y3pFN6FnqyYE+WosnUhDonBTCYUbkbph75FjzN+axoJth9iQlFnuDskAbYN96RXdhF7RjenRsjE+7rXu+ggRqUIKN5VQuBGpe/KLS1mzL5Plu46wfNcREg+Wvxmni5ONThEBZthp1ZjOzRvh5mLpvMAiUsUUbiqhcCNS9x09VszK3Rks23WEFbuPsD8jv9x6T1dnLo0KpHd0E3pFN6FdiC9OutxcpE5TuKmEwo1I/ZN8NJ8Vu4+wbFcGK3YdIeNYcbn1gd5u9GxljtfpHd2EiEAviyoVkQulcFMJhRuR+s1uN9iRnus4hbV671Hyi8vKtYkI9KT38YHJPVs1prGPBieL1HYKN5VQuBFpWIpL7Ww6kOUIOxuSsii1l/9nr12IL/GtGhPf0hycrPvriNQ+CjeVULgRadjyikpZs/coy46Hne1p5efAstmgQzN/M+y0akz3FoG6EkukFlC4qYTCjYicKiOviFV7jrJyzxFW7M5gz+Fj5dY7O9noFG6GnZ6tmtA1spGmiBCxgMJNJRRuRKQy6TmFrNydwcrdGazYc4TkowXl1rs5O9G5eYAj7FwSEaDLzkVqgMJNJRRuROR8JB/NZ+WeDEfgOXWKCAAPVye6twjkspaN6dmqMR3D/HFxVtgRqWoKN5VQuBGRC2UYBnuPHGPlngxW7M5g1e6M0y4793F34dKoQOJbmmN2YkP9dI8dkSqgcFMJhRsRqSqGYfB7eh4rd5vjdVbtySCnsLRcG18PF7o0b0S3yEZ0axHIJREBeLppzI7I+VK4qYTCjYhUlzK7wbbUHHO8zu4j/Lr3KMf+cI8dFycb7Zv50a1FIN0iG9G1RSOa+npYVLFI3aFwUwmFGxGpKaVldral5rJ2/1HW7s9k7b6jpOcUndYusrEXXSMb0S0ykG4tGhEd5KNTWSJ/oHBTCYUbEbGKYRgcyCxg3f5MM/Dsy2RHei5//FfY39PVDDstzMATF+6vy8+lwVO4qYTCjYjUJtkFJWxIymTtPjPwbEzOorDEXq6Nq7ONjmH+dGsReLyHp5GmjJAGR+GmEgo3IlKblZTZSTyYw9p9R4/38GRyOPf0U1ktm3jTNbIRcREBdAzzp12Ir3p3pF5TuKmEwo2I1CWGYZB0NP94z445bmfnobzT2jk72Wjd1If2zfzpGOZHhzB/YkL98NbUEVJPKNxUQuFGROq6rPxi1idlsm5/JltSctiSkn3a/XbAnCerZRNvOoT50zHMn/bN/Gkf5oefhyYGlbpH4aYSCjciUt8YhkFaTqEj6GxJyWbLwewKr8wC8+qsDmH+dGjmT4cwPzo086eRt1sNVy1yfhRuKqFwIyINxaHcQhIP5pCYks3mlGy2pOSQklVQYduwAE9H0OkQZvbw6P47Upso3FRC4UZEGrLMY8UkHsxhy0Ez8CSmZLMvI7/Ctk193YkJ9SO2mZ/5M9SXFo29NXeWWELhphIKNyIi5eUUlrD14KmntHLYfTjvtPvvALi7ONE2xJeYED9iQn2JCfWjXagf/p4axyPVS+GmEgo3IiJnd6yolO1pOWxNzWVbag7bUnPYkZZL/h+mkzghLMDT0bsTE2r29DQP9NKdlqXKKNxUQuFGROTC2O0G+4/mO8KO+cg94zgebzdn2oWe7OGJCfWjXYgvXm66PF3On8JNJRRuRESqVlZ+MdtO6eHZlpbD7+l5FJfaT2trs0GLxt7EhPoevyeP+dDVWnI2CjeVULgREal+pWV29hw5xrbUHLYe7+HZlppT4d2WAZoHetEx3J9O4f50DAugY7g/ProBoZxC4aYSCjciItY5klfk6OHZnJLD5gNZFV6tdeIGhJ3CzaATFx5A+2Z+mmKiAVO4qYTCjYhI7ZKdX8LmlGx+S8nit2TzEvWKxvE4O9loE+xLXJg/cRH+xIUF0DbEFzcXXZreECjcVELhRkSk9jucW8SWlGw2Hchi84FsNh3I5kje6ae03JydiAn1Je54D0+n8ACim/rgrKu06h2Fm0oo3IiI1D0nppjYlJzN5pQsfjuQzW8HsskuKDmtraerMx3C/GgX4kfLIG9aBfnQMsibZv6eujS9DlO4qYTCjYhI/XBixnQz6JiBZ0tKNsfOcC8eD1cnopr40CrIm5ZB5s9WQT5ENfHW7Ol1QJ0JN5MnT+brr79m+/bteHp60rNnT55//nnatm17xtfMmDGDv/zlL+WWubu7U1hYeE7vqXAjIlJ/2e0Ge47k8duBbHYdymP34Tx2Hz7G/oxjlJSd+esu1N/D0cNz6s9Qfw9sNvX21Abn8/1taVRdsmQJo0aNonv37pSWlvLkk09y7bXXsnXrVry9vc/4Oj8/P3bs2OF4rr94IiIC4ORkI7qpL9FNfcstLy2zk5xZwJ7DZuDZc/iY42fGsWJSswtJzS5k2a4j5V7n6epMy1N6ehw/m/jg6aYrt2orS8PN3Llzyz2fMWMGTZs2Zd26dVxxxRVnfJ3NZiMkJKS6yxMRkXrCxdmJqCbeRDXx5pqY4HLrsvKL2X1K2Nl9PAAlZeRTUFJmzqx+MOe0bYYFeNKqqQ/RQT5ENzVDT3RTHxr7uNfUbskZ1KqTjNnZ2QAEBgZW2i4vL4/IyEjsdjtdunTh2WefpX379hW2LSoqoqjo5Aj7nJzT/4KKiEjDFeDlRtdIN7pGNiq3vKTMTtLR/FN6efIcISgrv4SUrAJSsgpY+vvhcq9r5OVKq+OBxww95s+wAA1orim1ZkCx3W7nxhtvJCsri2XLlp2x3cqVK9m5cydxcXFkZ2fz0ksvsXTpUhITEwkPDz+t/YQJE5g4ceJpyzXmRkRELtTRY8WOMT27DuU5fj+QWfE8W2DOqN7yD7080U19aNHYWzcnPAd1ZkDxqR588EHmzJnDsmXLKgwpZ1JSUkJMTAxDhgzhmWeeOW19RT03ERERCjciIlLlCorLHKe1dh8ye3p2Hcpj75FjFJedPtcWgJMNIgK9Tvb2HB/QHNnYmyY+bhpXelydGVB8wujRo/nhhx9YunTpeQUbAFdXVzp37syuXbsqXO/u7o67u85/iohI9fN0c6ZDmD8dwvzLLS8ts3Mgs8Ds5TkefHYd7/XJLSxlf0Y++zPy+Xn7oXKv83JzpnmgF5GNvYhs7H3y90BvmgV44OKsuzNXxNJwYxgGDz/8MN988w2LFy8mKirqvLdRVlbG5s2bGTBgQDVUKCIicvFcnJ1o0cSbFk286cvJAc2GYXA4r+j4aa1jZug53tNzMLuA/OIytqflsj0t97RtOjvZCAvwJLKxlyP0NA/0Ph6EvPByqxX9F5awdM9HjRrFJ598wrfffouvry9paWkA+Pv74+npCcCwYcMICwtj8uTJAEyaNInLLruM6OhosrKyePHFF9m/fz8jRoywbD9EREQuhM1mo6mvB019PejZqkm5dUWlZRzILCApI5/9GcfYfzTf/P1oPklH8ykuNQc8Jx09feJRgCY+7sd7ebxo3rh8+GnsXb9Pd1kabqZOnQrAlVdeWW759OnTGT58OABJSUk4OZ3sdsvMzGTkyJGkpaXRqFEjunbtyooVK4iNja2pskVERKqdu4szrYLMq63+yG43SM8tZH/GicBzzPz9qHl6K7ughCN5RRzJK2Ld/szTXu/l5kxYgCdhjTzL/Qxv5El4Iy+CfNzr9JVdtWZAcU3RHYpFRKS+y84vYf/RY46wcyIAJWXkk5pTyNm++d2cnQgN8DCDT7nw40V4I09C/D1wreHxPnVuQLGIiIhUHX8vV+K8AogLDzhtXWFJGQeP36MnJfPkzwPHf6blFFJcZncMcq6Ikw2C/TxOCz6OnqAAT0vv4KxwIyIi0oB4uDrTMsiHlhWc7gLzyq60nMJywSclq3wIKi61O6asWFvBaa/WTX2Y/1if6t6VM1K4EREREQcXZ6fjp5+8KlxvtxscOVZ0evg5/vNAZgFhjTxruOryFG5ERETknDk5nbzCq3PzRqetNwyDotKKb1hYU3T3HxEREakyNpvN8ukkFG5ERESkXlG4ERERkXpF4UZERETqFYUbERERqVcUbkRERKReUbgRERGRekXhRkREROoVhRsRERGpVxRuREREpF5RuBEREZF6ReFGRERE6hWFGxEREalXFG5ERESkXnGxuoCaZhgGADk5ORZXIiIiIufqxPf2ie/xyjS4cJObmwtARESExZWIiIjI+crNzcXf37/SNjbjXCJQPWK32zl48CC+vr7YbLYq3XZOTg4REREkJyfj5+dXpduubbSv9VdD2l/ta/3VkPa3oeyrYRjk5ubSrFkznJwqH1XT4HpunJycCA8Pr9b38PPzq9d/wU6lfa2/GtL+al/rr4a0vw1hX8/WY3OCBhSLiIhIvaJwIyIiIvWKwk0Vcnd3Z/z48bi7u1tdSrXTvtZfDWl/ta/1V0Pa34a0r+eqwQ0oFhERkfpNPTciIiJSryjciIiISL2icCMiIiL1isKNiIiI1CsKN+fpzTffpEWLFnh4eNCjRw9+/fXXStt/8cUXtGvXDg8PDzp27MiPP/5YQ5VeuMmTJ9O9e3d8fX1p2rQpgwcPZseOHZW+ZsaMGdhstnIPDw+PGqr44kyYMOG02tu1a1fpa+ricQVo0aLFaftqs9kYNWpUhe3r0nFdunQpN9xwA82aNcNmszFr1qxy6w3D4F//+hehoaF4enrSt29fdu7cedbtnu9nvqZUtr8lJSU8/vjjdOzYEW9vb5o1a8awYcM4ePBgpdu8kM9CTTjbsR0+fPhpdffv3/+s262Nx/Zs+1rR59dms/Hiiy+ecZu19bhWJ4Wb8/DZZ5/x2GOPMX78eNavX0+nTp1ISEjg0KFDFbZfsWIFQ4YM4d5772XDhg0MHjyYwYMHs2XLlhqu/PwsWbKEUaNGsWrVKubPn09JSQnXXnstx44dq/R1fn5+pKamOh779++voYovXvv27cvVvmzZsjO2ravHFWDNmjXl9nP+/PkA3HrrrWd8TV05rseOHaNTp068+eabFa5/4YUXeO2113j77bdZvXo13t7eJCQkUFhYeMZtnu9nviZVtr/5+fmsX7+ep59+mvXr1/P111+zY8cObrzxxrNu93w+CzXlbMcWoH///uXq/vTTTyvdZm09tmfb11P3MTU1lffffx+bzcYtt9xS6XZr43GtVoacs0svvdQYNWqU43lZWZnRrFkzY/LkyRW2v+2224yBAweWW9ajRw/j/vvvr9Y6q9qhQ4cMwFiyZMkZ20yfPt3w9/evuaKq0Pjx441OnTqdc/v6clwNwzD++te/Gq1atTLsdnuF6+vqcQWMb775xvHcbrcbISEhxosvvuhYlpWVZbi7uxuffvrpGbdzvp95q/xxfyvy66+/GoCxf//+M7Y538+CFSra17vvvtsYNGjQeW2nLhzbczmugwYNMq6++upK29SF41rV1HNzjoqLi1m3bh19+/Z1LHNycqJv376sXLmywtesXLmyXHuAhISEM7avrbKzswEIDAystF1eXh6RkZFEREQwaNAgEhMTa6K8KrFz506aNWtGy5YtGTp0KElJSWdsW1+Oa3FxMR999BH33HNPpZPI1uXjesLevXtJS0srd9z8/f3p0aPHGY/bhXzma7Ps7GxsNhsBAQGVtjufz0JtsnjxYpo2bUrbtm158MEHycjIOGPb+nJs09PTmT17Nvfee+9Z29bV43qhFG7O0ZEjRygrKyM4OLjc8uDgYNLS0ip8TVpa2nm1r43sdjuPPvoovXr1okOHDmds17ZtW95//32+/fZbPvroI+x2Oz179uTAgQM1WO2F6dGjBzNmzGDu3LlMnTqVvXv3cvnll5Obm1th+/pwXAFmzZpFVlYWw4cPP2ObunxcT3Xi2JzPcbuQz3xtVVhYyOOPP86QIUMqnVjxfD8LtUX//v358MMPWbhwIc8//zxLlizhuuuuo6ysrML29eXYfvDBB/j6+nLzzTdX2q6uHteL0eBmBZfzM2rUKLZs2XLW87Px8fHEx8c7nvfs2ZOYmBimTZvGM888U91lXpTrrrvO8XtcXBw9evQgMjKSzz///Jz+R1RXvffee1x33XU0a9bsjG3q8nEVU0lJCbfddhuGYTB16tRK29bVz8Idd9zh+L1jx47ExcXRqlUrFi9ezDXXXGNhZdXr/fffZ+jQoWcd5F9Xj+vFUM/NOWrSpAnOzs6kp6eXW56enk5ISEiFrwkJCTmv9rXN6NGj+eGHH1i0aBHh4eHn9VpXV1c6d+7Mrl27qqm66hMQEECbNm3OWHtdP64A+/fvZ8GCBYwYMeK8XldXj+uJY3M+x+1CPvO1zYlgs3//fubPn19pr01FzvZZqK1atmxJkyZNzlh3fTi2v/zyCzt27DjvzzDU3eN6PhRuzpGbmxtdu3Zl4cKFjmV2u52FCxeW+5/tqeLj48u1B5g/f/4Z29cWhmEwevRovvnmG37++WeioqLOextlZWVs3ryZ0NDQaqiweuXl5bF79+4z1l5Xj+uppk+fTtOmTRk4cOB5va6uHteoqChCQkLKHbecnBxWr159xuN2IZ/52uREsNm5cycLFiygcePG572Ns30WaqsDBw6QkZFxxrrr+rEFs+e1a9eudOrU6bxfW1eP63mxekRzXTJz5kzD3d3dmDFjhrF161bjvvvuMwICAoy0tDTDMAzjz3/+s/HEE0842i9fvtxwcXExXnrpJWPbtm3G+PHjDVdXV2Pz5s1W7cI5efDBBw1/f39j8eLFRmpqquORn5/vaPPHfZ04caIxb948Y/fu3ca6deuMO+64w/Dw8DASExOt2IXz8re//c1YvHixsXfvXmP58uVG3759jSZNmhiHDh0yDKP+HNcTysrKjObNmxuPP/74aevq8nHNzc01NmzYYGzYsMEAjJdfftnYsGGD4+qg5557zggICDC+/fZb47fffjMGDRpkREVFGQUFBY5tXH311cbrr7/ueH62z7yVKtvf4uJi48YbbzTCw8ONjRs3lvscFxUVObbxx/0922fBKpXta25urjF27Fhj5cqVxt69e40FCxYYXbp0MVq3bm0UFhY6tlFXju3Z/h4bhmFkZ2cbXl5extSpUyvcRl05rtVJ4eY8vf7660bz5s0NNzc349JLLzVWrVrlWNenTx/j7rvvLtf+888/N9q0aWO4ubkZ7du3N2bPnl3DFZ8/oMLH9OnTHW3+uK+PPvqo488lODjYGDBggLF+/fqaL/4C3H777UZoaKjh5uZmhIWFGbfffruxa9cux/r6clxPmDdvngEYO3bsOG1dXT6uixYtqvDv7Yn9sdvtxtNPP20EBwcb7u7uxjXXXHPan0FkZKQxfvz4cssq+8xbqbL93bt37xk/x4sWLXJs44/7e7bPglUq29f8/Hzj2muvNYKCggxXV1cjMjLSGDly5Gkhpa4c27P9PTYMw5g2bZrh6elpZGVlVbiNunJcq5PNMAyjWruGRERERGqQxtyIiIhIvaJwIyIiIvWKwo2IiIjUKwo3IiIiUq8o3IiIiEi9onAjIiIi9YrCjYiIiNQrCjci0uAsXrwYm81GVlaW1aWISDVQuBEREZF6ReFGRERE6hWFGxGpcXa7ncmTJxMVFYWnpyedOnXiyy+/BE6eMpo9ezZxcXF4eHhw2WWXsWXLlnLb+Oqrr2jfvj3u7u60aNGCKVOmlFtfVFTE448/TkREBO7u7kRHR/Pee++Va7Nu3Tq6deuGl5cXPXv2ZMeOHY51mzZt4qqrrsLX1xc/Pz+6du3K2rVrq+lPRESqksKNiNS4yZMn8+GHH/L222+TmJjImDFjuOuuu1iyZImjzd///nemTJnCmjVrCAoK4oYbbqCkpAQwQ8ltt93GHXfcwebNm5kwYQJPP/00M2bMcLx+2LBhfPrpp7z22mts27aNadOm4ePjU66Of/7zn0yZMoW1a9fi4uLCPffc41g3dOhQwsPDWbNmDevWreOJJ57A1dW1ev9gRKRqWD1zp4g0LIWFhYaXl5exYsWKcsvvvfdeY8iQIY5ZkWfOnOlYl5GRYXh6ehqfffaZYRiGceeddxr9+vUr9/q///3vRmxsrGEYhrFjxw4DMObPn19hDSfeY8GCBY5ls2fPNgCjoKDAMAzD8PX1NWbMmHHxOywiNU49NyJSo3bt2kV+fj79+vXDx8fH8fjwww/ZvXu3o118fLzj98DAQNq2bcu2bdsA2LZtG7169Sq33V69erFz507KysrYuHEjzs7O9OnTp9Ja4uLiHL+HhoYCcOjQIQAee+wxRowYQd++fXnuuefK1SYitZvCjYjUqLy8PABmz57Nxo0bHY+tW7c6xt1cLE9Pz3Nqd+ppJpvNBpjjgQAmTJhAYmIiAwcO5OeffyY2NpZvvvmmSuoTkeqlcCMiNSo2NhZ3d3eSkpKIjo4u94iIiHC0W7VqleP3zMxMfv/9d2JiYgCIiYlh+fLl5ba7fPly2rRpg7OzMx07dsRut5cbw3Mh2rRpw5gxY/jpp5+4+eabmT59+kVtT0RqhovVBYhIw+Lr68vYsWMZM2YMdrud3r17k52dzfLly/Hz8yMyMhKASZMm0bhxY4KDg/nnP/9JkyZNGDx4MAB/+9vf6N69O8888wy33347K1eu5I033uCtt94CoEWLFtx9993cc889vPbaa3Tq1In9+/dz6NAhbrvttrPWWFBQwN///nf+9Kc/ERUVxYEDB1izZg233HJLtf25iEgVsnrQj4g0PHa73XjllVeMtm3bGq6urkZQUJCRkJBgLFmyxDHY9/vvvzfat29vuLm5GZdeeqmxadOmctv48ssvjdjYWMPV1dVo3ry58eKLL5ZbX1BQYIwZM8YIDQ013NzcjOjoaOP99983DOPkgOLMzExH+w0bNhiAsXfvXqOoqMi44447jIiICMPNzc1o1qyZMXr0aMdgYxGp3WyGYRgW5ysREYfFixdz1VVXkZmZSUBAgNXliEgdpDE3IiIiUq8o3IiIiEi9otNSIiIiUq+o50ZERETqFYUbERERqVcUbkRERKReUbgRERGRekXhRkREROoVhRsRERGpVxRuREREpF5RuBEREZF6ReFGRERE6pX/B8ewpZccXJ+6AAAAAElFTkSuQmCC\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# saving the model with last parameter\n",
        "model.save('./latest_model.h5')"
      ],
      "metadata": {
        "id": "BrGQaSY5cp1O"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_feat(filename):\n",
        "    # load the model\n",
        "    model = VGG16()\n",
        "    # re-structure the model\n",
        "    model = Model(inputs=model.inputs, outputs=model.layers[-2].output)\n",
        "    # load the photo\n",
        "    image = load_img(filename, target_size=(224, 224))\n",
        "    # convert the image pixels to a numpy array\n",
        "    image = img_to_array(image)\n",
        "    # reshape data for the model\n",
        "    image = image.reshape((1, image.shape[0], image.shape[1], image.shape[2]))\n",
        "    # prepare the image for the VGG model\n",
        "    image = preprocess_input(image)\n",
        "    # get features\n",
        "    feature = model.predict(image, verbose=0)\n",
        "    return feature\n",
        "\n",
        "# map an integer to a word\n",
        "def word_for_id(integer, tokenizr):\n",
        "    for word, index in tokenizr.word_index.items():\n",
        "        if index == integer:\n",
        "            return word\n",
        "    return None"
      ],
      "metadata": {
        "id": "TwWfb0TGAdTF"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_desc(model, tokenizer, photo, max_length):\n",
        "    # seed the generation process\n",
        "    in_text = 'startseq'\n",
        "    # iterate over the whole length of the sequence\n",
        "    for i in range(max_length):\n",
        "        # integer encode input sequence\n",
        "        sequence = tokenizer.texts_to_sequences([in_text])[0]\n",
        "        # pad input\n",
        "        sequence = pad_sequences([sequence], maxlen=max_length)\n",
        "        # predict next word\n",
        "        yhat = model.predict([photo,sequence], verbose=0)\n",
        "        # convert probability to integer\n",
        "        yhat = np.argmax(yhat)\n",
        "        # map integer to word\n",
        "        word = word_for_id(yhat, tokenizer)\n",
        "        # stop if we cannot map the word\n",
        "        if word is None:\n",
        "            break\n",
        "        # append as input for generating the next word\n",
        "        in_text += ' ' + word\n",
        "        # stop if we predict the end of the sequence\n",
        "        if word == 'endseq':\n",
        "            break\n",
        "    return in_text"
      ],
      "metadata": {
        "id": "N4goKm8tAlci"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import load_model\n",
        "# load the model\n",
        "modl = load_model('./latest_model.h5')\n",
        "\n",
        "# generate description\n",
        "tokenizr = Tokenizer()\n",
        "tokenizr.fit_on_texts([caption for image, caption in new_captions_dict.items() if image in train_validate_images])\n",
        "max_length = 30\n",
        "\n",
        "for count in range(10):\n",
        "\n",
        "    photo = extract_feat('{}.jpg'.format(image_dataset_path+'/'+train_validate_images[count]))\n",
        "\n",
        "    # generate description\n",
        "    description = generate_desc(modl, tokenizr, photo, max_length)\n",
        "    print(\"Predicted caption -> \", description)\n",
        "    print()\n",
        "    print(\"Actual caption -> \", new_captions_dict[train_validate_images[count]])\n",
        "    print('*********************************************************************')\n",
        "    print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VRvG_G1-Ap5D",
        "outputId": "90db675c-d355-4636-e2f0-d4a4711f621c"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted caption ->  startseq man in red shirt and jeans is standing in the sand endseq\n",
            "\n",
            "Actual caption ->  startseq baby is lifted into the air by man wearing no shirt endseq\n",
            "*********************************************************************\n",
            "\n",
            "Predicted caption ->  startseq brown and white dog is running in the snow endseq\n",
            "\n",
            "Actual caption ->  startseq black and white dog is running through the sand on beach endseq\n",
            "*********************************************************************\n",
            "\n",
            "Predicted caption ->  startseq man in red shirt and sunglasses walks down city street endseq\n",
            "\n",
            "Actual caption ->  startseq large man at party with drink in his right hand endseq\n",
            "*********************************************************************\n",
            "\n",
            "Predicted caption ->  startseq boy in red shirt is standing in the sand endseq\n",
            "\n",
            "Actual caption ->  startseq boy in blue shirt is walking along tan and blue wall endseq\n",
            "*********************************************************************\n",
            "\n",
            "Predicted caption ->  startseq brown dog is running through the snow endseq\n",
            "\n",
            "Actual caption ->  startseq brown dog is chewing on bone with stuffed animal underneath it endseq\n",
            "*********************************************************************\n",
            "\n",
            "Predicted caption ->  startseq boy in red shirt is playing guitar endseq\n",
            "\n",
            "Actual caption ->  startseq little girl rides toy bike and laughs endseq\n",
            "*********************************************************************\n",
            "\n",
            "Predicted caption ->  startseq man in red wetsuit is climbing rock face endseq\n",
            "\n",
            "Actual caption ->  startseq red covered boat racing across the water endseq\n",
            "*********************************************************************\n",
            "\n",
            "Predicted caption ->  startseq boy in blue life life life cap and red cap swimming trunks in pool endseq\n",
            "\n",
            "Actual caption ->  startseq woman and three children are jumping into swimming pool endseq\n",
            "*********************************************************************\n",
            "\n",
            "Predicted caption ->  startseq brown dog is running through the snow endseq\n",
            "\n",
            "Actual caption ->  startseq golden retriever on leash moves through snow endseq\n",
            "*********************************************************************\n",
            "\n",
            "Predicted caption ->  startseq boy in blue shirt is riding bike on the ledge endseq\n",
            "\n",
            "Actual caption ->  startseq boy and his bike leaps into the air endseq\n",
            "*********************************************************************\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install astropy>=3.1\n",
        "!pip install sunpy\n",
        "!pip install streamlit==1.24.0 --quiet"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xr3QwIzjBo6G",
        "outputId": "fd765b9a-50ef-4ada-f47b-1095339a2dcc"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting sunpy\n",
            "  Downloading sunpy-5.0.1-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.3 MB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/3.3 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.2/3.3 MB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/3.3 MB\u001b[0m \u001b[31m27.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m34.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: astropy!=5.1.0,>=5.0.6 in /usr/local/lib/python3.10/dist-packages (from sunpy) (5.3.4)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from sunpy) (1.23.5)\n",
            "Requirement already satisfied: packaging>=19.0 in /usr/local/lib/python3.10/dist-packages (from sunpy) (23.2)\n",
            "Collecting parfive[ftp]>=2.0.0 (from sunpy)\n",
            "  Downloading parfive-2.0.2-py3-none-any.whl (26 kB)\n",
            "Requirement already satisfied: pyerfa>=2.0 in /usr/local/lib/python3.10/dist-packages (from astropy!=5.1.0,>=5.0.6->sunpy) (2.0.1.1)\n",
            "Requirement already satisfied: PyYAML>=3.13 in /usr/local/lib/python3.10/dist-packages (from astropy!=5.1.0,>=5.0.6->sunpy) (6.0.1)\n",
            "Requirement already satisfied: tqdm>=4.27.0 in /usr/local/lib/python3.10/dist-packages (from parfive[ftp]>=2.0.0->sunpy) (4.66.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from parfive[ftp]>=2.0.0->sunpy) (3.8.6)\n",
            "Collecting aioftp>=0.17.1 (from parfive[ftp]>=2.0.0->sunpy)\n",
            "  Downloading aioftp-0.21.4-py3-none-any.whl (37 kB)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->parfive[ftp]>=2.0.0->sunpy) (23.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->parfive[ftp]>=2.0.0->sunpy) (3.3.2)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->parfive[ftp]>=2.0.0->sunpy) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->parfive[ftp]>=2.0.0->sunpy) (4.0.3)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->parfive[ftp]>=2.0.0->sunpy) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->parfive[ftp]>=2.0.0->sunpy) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->parfive[ftp]>=2.0.0->sunpy) (1.3.1)\n",
            "Requirement already satisfied: idna>=2.0 in /usr/local/lib/python3.10/dist-packages (from yarl<2.0,>=1.0->aiohttp->parfive[ftp]>=2.0.0->sunpy) (3.4)\n",
            "Installing collected packages: aioftp, parfive, sunpy\n",
            "Successfully installed aioftp-0.21.4 parfive-2.0.2 sunpy-5.0.1\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.9/8.9 MB\u001b[0m \u001b[31m56.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m164.8/164.8 kB\u001b[0m \u001b[31m22.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m190.6/190.6 kB\u001b[0m \u001b[31m22.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.8/4.8 MB\u001b[0m \u001b[31m99.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m82.1/82.1 kB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m341.8/341.8 kB\u001b[0m \u001b[31m37.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile app3.py\n",
        "import streamlit as st\n",
        "from PIL import Image\n",
        "from keras.applications.vgg16 import VGG16\n",
        "from keras.preprocessing.image import load_img\n",
        "from keras.preprocessing.image import img_to_array\n",
        "from keras.applications.vgg16 import preprocess_input\n",
        "import numpy as np\n",
        "from keras.models import Model, load_model\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.utils import to_categorical, plot_model\n",
        "import os\n",
        "\n",
        "st.title(\"IMAGE CAPTIONING\")\n",
        "st.text(\"The following AI will help you write captions to images\")\n",
        "image_dataset_path = '/content/drive/MyDrive/codetice/input/Flicker8k_Dataset'\n",
        "caption_dataset_path = '/content/drive/MyDrive/codetice/input/Flickr8k_text/Flickr8k.token.txt'\n",
        "\n",
        "# load the caption file & read it\n",
        "def load_caption_file(path):\n",
        "\n",
        "    # dictionary to store captions\n",
        "    captions_dict = {}\n",
        "\n",
        "    # iterate through the file\n",
        "    for caption in open(path):\n",
        "\n",
        "        # caption has format-> 1000268201_693b08cb0e.jpg#0  A child in a pink dress is climbing up a set of stairs in an entry way .\n",
        "        tokens = caption.split()\n",
        "        caption_id, caption_text = tokens[0].split('.')[0], tokens[1:]\n",
        "        caption_text = ' '.join(caption_text)\n",
        "\n",
        "        # save it in the captions dictionary\n",
        "        if caption_id not in captions_dict:\n",
        "            captions_dict[caption_id] = caption_text\n",
        "\n",
        "    return captions_dict\n",
        "\n",
        "# call the function\n",
        "captions_dict = load_caption_file(caption_dataset_path)\n",
        "\n",
        "# clean the captions\n",
        "import string\n",
        "\n",
        "# dictionary to store the cleaned captions\n",
        "new_captions_dict = {}\n",
        "\n",
        "# prepare translation table for removing punctuation. third argument is the list of punctuations we want to remove\n",
        "table = str.maketrans('', '', string.punctuation)\n",
        "\n",
        "# loop through the dictionary\n",
        "for caption_id, caption_text in captions_dict.items():\n",
        "    # tokenize the caption_text\n",
        "    caption_text = caption_text.split()\n",
        "    # convert it into lower case\n",
        "    caption_text = [token.lower() for token in caption_text]\n",
        "    # remove punctuation from each token\n",
        "    caption_text = [token.translate(table) for token in caption_text]\n",
        "    # remove all the single letter tokens like 'a', 's'\n",
        "    caption_text = [token for token in caption_text if len(token)>1]\n",
        "    # store the cleaned captions\n",
        "    new_captions_dict[caption_id] = 'startseq ' + ' '.join(caption_text) + ' endseq'\n",
        "\n",
        "del captions_dict\n",
        "\n",
        "caption_images_list = []\n",
        "\n",
        "image_index = list(new_captions_dict.keys())\n",
        "\n",
        "caption_images_list = [ image.split('.')[0] for image in os.listdir(image_dataset_path) if image.split('.')[0] in image_index ]\n",
        "\n",
        "train_validate_images = caption_images_list[0:8081]\n",
        "\n",
        "def extract_feat(filename):\n",
        "    # load the model\n",
        "    model = VGG16()\n",
        "    # re-structure the model\n",
        "    model = Model(inputs=model.inputs, outputs=model.layers[-2].output)\n",
        "    # load the photo\n",
        "    image = load_img(filename, target_size=(224, 224))\n",
        "    # convert the image pixels to a numpy array\n",
        "    image = img_to_array(image)\n",
        "    # reshape data for the model\n",
        "    image = image.reshape((1, image.shape[0], image.shape[1], image.shape[2]))\n",
        "    # prepare the image for the VGG model\n",
        "    image = preprocess_input(image)\n",
        "    # get features\n",
        "    feature = model.predict(image, verbose=0)\n",
        "    return feature\n",
        "\n",
        "# map an integer to a word\n",
        "def word_for_id(integer, tokenizr):\n",
        "    for word, index in tokenizr.word_index.items():\n",
        "        if index == integer:\n",
        "            return word\n",
        "    return None\n",
        "\n",
        "def generate_desc(model, tokenizer, photo, max_length):\n",
        "    # seed the generation process\n",
        "    in_text = 'startseq'\n",
        "    # iterate over the whole length of the sequence\n",
        "    for i in range(max_length):\n",
        "        # integer encode input sequence\n",
        "        sequence = tokenizer.texts_to_sequences([in_text])[0]\n",
        "        # pad input\n",
        "        sequence = pad_sequences([sequence], maxlen=max_length)\n",
        "        # predict next word\n",
        "        yhat = model.predict([photo,sequence], verbose=0)\n",
        "        # convert probability to integer\n",
        "        yhat = np.argmax(yhat)\n",
        "        # map integer to word\n",
        "        word = word_for_id(yhat, tokenizer)\n",
        "        # stop if we cannot map the word\n",
        "        if word is None:\n",
        "            break\n",
        "        # append as input for generating the next word\n",
        "        in_text += ' ' + word\n",
        "        # stop if we predict the end of the sequence\n",
        "        if word == 'endseq':\n",
        "            break\n",
        "    return in_text\n",
        "\n",
        "\n",
        "\n",
        "def load_image(image_file):\n",
        "\timg = Image.open(image_file)\n",
        "\treturn img\n",
        "\n",
        "uploaded_files = st.file_uploader(\"Choose a jpg file\",type='jpg', accept_multiple_files=True)\n",
        "for uploaded_file in uploaded_files:\n",
        "    bytes_data = uploaded_file.read()\n",
        "    img = load_image( uploaded_file)\n",
        "    with open(uploaded_file.name,'wb') as f:\n",
        "       f.write(uploaded_file.getbuffer())\n",
        "    # load the model\n",
        "    modl = load_model('./latest_model.h5')\n",
        "    # generate description\n",
        "    tokenizr = Tokenizer()\n",
        "    tokenizr.fit_on_texts([caption for image, caption in new_captions_dict.items() if image in train_validate_images])\n",
        "    max_length = 30\n",
        "    photo = extract_feat('/content/{}'.format(uploaded_file.name))\n",
        "    # generate description\n",
        "    description = generate_desc(modl, tokenizr, photo, max_length)\n",
        "    description=description.replace('startseq', '')\n",
        "    description=description.replace('endseq', '')\n",
        "    st.image(img,width=250,caption=description)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XVg0lm7tA0XG",
        "outputId": "6e42b972-2f70-4320-d18e-68cad1b8acde"
      },
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting app3.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!streamlit run app3.py & npx localtunnel --port 8501 & curl ipv4.icanhazip.com"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hOUnnwzZCTc4",
        "outputId": "a5f880e4-b9a7-41f6-f5cc-a245306bc750"
      },
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "34.170.52.125\n",
            "[##................] - fetchMetadata: sill resolveWithNewModule ms@2.1.2 checki\u001b[0m\u001b[K\n",
            "Collecting usage statistics. To deactivate, set browser.gatherUsageStats to False.\n",
            "\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m\u001b[1m  You can now view your Streamlit app in your browser.\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m  Network URL: \u001b[0m\u001b[1mhttp://172.28.0.12:8501\u001b[0m\n",
            "\u001b[34m  External URL: \u001b[0m\u001b[1mhttp://34.170.52.125:8501\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[K\u001b[?25hnpx: installed 22 in 3.207s\n",
            "your url is: https://soft-bobcats-yell.loca.lt\n",
            "2023-11-17 13:32:08.470739: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2023-11-17 13:32:08.471701: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2023-11-17 13:32:08.472051: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2023-11-17 13:32:10.906743: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "2023-11-17 13:32:38.778000: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:47] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "2023-11-17 13:32:43.732923: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 411041792 exceeds 10% of free system memory.\n",
            "\u001b[34m  Stopping...\u001b[0m\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}